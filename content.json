{"meta":{"title":"老陕小张","subtitle":"老陕小张学技术","description":"欢迎来到skillixx.com，这是一个由老陕小张创建的IT技术网站。我们致力于分享与运维相关的技术，包括Python、Docker、ansible、Linux、Windows、chatgpt、GitHub等比较好的开源项目。此外，我们还会介绍一些比较好的Linux工具和Windows工具的使用和推荐，以及常见问题的处理方法。如果你是一名运维工程师，我们也会为你提供学习资料和学校路线，帮助你更好地成长和发展。无论你是初学者还是资深专家，我们都欢迎你来到skillixx.com，与我们一起探索IT技术的无限可能！","author":"老陕小张","url":"https://skillixx.com"},"pages":[],"posts":[{"title":"Jenkins从入门到实战","slug":"jenkinsstudy","date":"2023-07-14T10:18:53.000Z","updated":"2023-07-14T10:30:09.991Z","comments":false,"path":"30edc0d5.html","link":"","permalink":"https://skillixx.com/30edc0d5.html","excerpt":"","text":"一、DevOps介绍软件开发最开始是由两个团队组成: 开发计划由开发团队从头开始设计和整体系统的构建。需要系统不停的迭代更新。 运维团队将开发团队的Code进行测试后部署上线。希望系统稳定安全运行。 这看似两个目标不同的团队需要协同完成一个软件的开发。 在开发团队指定好计划并完成coding后，需要提供到运维团队。 运维团队向开发团队反馈需要修复的BUG以及一些需要返工的任务。 这时开发团队需要经常等待运维团队的反馈。这无疑延长了事件并推迟了整个软件开发的周期。 会有一种方式，在开发团队等待的时候，让开发团队转移到下一个项目中。等待运维团队为之前的代码提供反馈。 可是这样就意味着一个完整的项目需要一个更长的周期才可以开发出最终代码。 基于现在的互联网现状，更推崇敏捷式开发，这样就导致项目的迭代速度更快，但是由于开发团队与运维团队的沟通问题，会导致新版本上线的时间成本很高。 这又违背的敏捷式开发的最初的目的。那么如果让开发团队和运维团队整合到成一个团队，协同应对一套软件呢?这就被称DevOps.DevOps，字面意思是Development &amp;Operations的缩写，也就是开发&amp;运维 虽然字面意思只涉及到开发团队和运维团队，其实QA测试团队也是参与其中的。 网上可以查看到DevOops的符合类似一个无穷大符合 二、Code阶段工具2.1 Git安装 Linux安装 yum install -y git Window安装 2.2 GitLab安装 硬件配置必须大于4G内存 拉取GitLab镜像 docker pull gitlab/gitlab-ce 准备docker-compose.yml version: \"3.1\" services: gitlab: image: \"gitlab/gitlab-ce:latest\" restart: always environment: GITLAB_OMNIBUS_CONFIG: | external_url \"http://192.168.75.100:8929\" gitlab_rails['gitlab_shell_ssh_port'] = 2224 ports: - \"8929:8929\" - \"2224:2224\" volumes: - \"./config:/etc/gitlab\" - \"./logs:/var/log/gitlab\" - \"./data:/var/opt/gitlab\" 启动容器（需要稍微等一下） docker-compose up -d 打开浏览器访问GitLab首页http://192.168.75.100:8929/ 登录GitLab 用户：root 密码在 initial_root_password文件中 cat config/initial_root_password 创建新项目在gitlab中 将源代码上传到gitlab中，我这里使用window中git工具 #进入项目代码文件夹 cd demoHello #初始化git仓库 git init #添加文件 git add . #提交到本地 git commit -m \"代码v1\" #配置远端仓库,点击gitlab项目中的clone查找项目仓库地址 git remote add origin http://192.168.75.100:8929/root/demoHello.git #push到远程仓库某分支，完成代码上传 git push -u origin \"master\" 查看代码上传结果 三、Build阶段工具构建Java项目的工具一般有二种选择，一个是Maven,一个是Gradle。 这里我们选择Maven作为项目的编译工具。 具体安装Maven流程不做阐述，但是需要确保配置好Maven仓库以及JDK编译版本。 四、Operate阶段工具!部署过程，会采用Docker进行部署，暂时只安装Docker即可，后续还需要安装kubenetes 4.1 Docker 安装 准备测试环境&amp;生产环境 下载Docker依赖组件 yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 设置下载Docker的镜像源为阿里云 yum-config-manager \\ --add-repo \\ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装Docker服务 yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin 安装成功后，启动Docker并设置开机自启 systemctl start docker systemctl enable docker 测试安装 [root@jenkins ~]# docker version Client: Docker Engine - Community Version: 24.0.4 API version: 1.43 Go version: go1.20.5 Git commit: 3713ee1 Built: Fri Jul 7 14:54:21 2023 OS/Arch: linux/amd64 Context: default 4.2 Docker-Compose安装#访问下载地址 https://github.com/docker/compose/tags #根据需要下载相应的版本 wget https://github.com/docker/compose/releases/download/v2.19.1/docker-compose-linux-x86_64 #将docker-compose-linux-x86_64 到/usr/local/bin mv docker-compose-linux-x86_64 /usr/local/bin #赋予执行取消 chmod a+x /usr/local/bin/docker-compose #验证是否安装成功 [root@jenkins ~]# docker-compose version Docker Compose version v2.19.1 五、Integrate工具持续集成、持续部署CI、CD的工具很多，其中Jenkins是一个开源的持续集成平台Jenkins涉及到将编写完毕的代码发布到测试环境和生产环境的任务，并且还涉及到了构建项目等任务。Jenkins需要大量的插件保证工作，安装成本较高，下面会基于Docker搭建Jenkins。 5.1 Jenkins介绍Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具Jenkins应用广泛，大多数互联网公司都采用Jenkins配合GitLab、Docker、K8s作为实现DevOps的核心工具.Jenkins最强大的就在于插件，Jenkins官方提供了大量的插件库，来自动化CI&#x2F;CD过程中的各种琐碎功能。 Jenkins最主要的工作就是将GitLab上可以构建的工程代码拉取并且进行构建，再根据流程可以选择发布到测试环境或是生产环境。 一般是GitLab上的代码经过大量的测试后，确定发行版本，再发布到生产环境。 CI&#x2F;CD可以理解为: CI过程即是通过Jenkins将代码拉取、构建、制作镜像交给测试人员测试。 1.持续集成:让软件代码可以持续的集成到主干上，并自动构建和测试。 CD过程即是通过Jenkins将打好标签的发行版本代码拉取、构建、制作镜像交给运维人员部署 1.持续交付:让经过持续集成的代码可以进行手动部署。 2.持续部署:让可以持续交付的代码随时随地的自动化部署。 5.2 Jenkins安装 了解一下jenkins官网是jenkins.io 拉取Jenkins镜像 docker pull jenkins/jenkins:2.413-jdk11 编写docker-compose.yml version: \"3.1\" services: jenkins: image: jenkins/jenkins:2.413-jdk11 container_name: jenkins ports: - 8080:8080 - 50000:50000 volumes: - ./data/:/var/jenkins_home/ 启动Jenkins容器 [root@jenkins ~]# docker-compose up -d 日志报错修改 # 查看日志 [root@jenkins ~]# docker logs -f jenkins touch: cannot touch '/var/jenkins_home/copy_reference_file.log': Permission denied Can not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions? # 修改bug [root@jenkins ~]# chmod -R 777 data/ # 重新启动容器 [root@jenkins ~]# docker-compose restart [+] Restarting 1/1 ✔ Container jenkins Started # 查看日志，如果显示密码，则服务正常 [root@jenkins ~]# docker logs -f jenkins 访问Jenkins服务在浏览器http://192.168.75.101:8080 重新启动Jenkins容器后，由于Jenkins需要下载大量内容，但是由于默认下载地址下载速度较慢，需要重新设置下载地址为国内镜像站 解锁Jenkins,查看Jenkins密码,并把命名填充 [root@jenkins ~]# cat data/secrets/initialAdminPassword 98ff1758a1c34e6aad615361b9975317 插件安装教学，选择插件来安装，最后选择安装，耐心等待，有可能安装失败，可以点击“继续”，可以进入Jenkins官网进行插件下载 创建管理员名，并选择默认访问路径 安装完成，来到Jenkins管理界面 安装本实验需要的插件，点击Manage Jenkins&#x2F;插件管理&#x2F;可选插件，依次安装本实验需要的基础插件git parameter，Publish Over SSH 5.3 Jenkins 入门配置5.3.1 配置Maven 构建代码 安装jdk #jdk文件下载官网 https://www.oracle.com/java/technologies/downloads/ #下载版本 jdk-8u141-linux-x64.tar.gz tar -xvf jdk-8u141-linux-x64.tar.gz -C /usr/local/ #解压文件 安装Maven #Maven文件下载官网 https://maven.apache.org/download.cgi #下载版本 apache-maven-3.5.4.zip unzip apache-maven-3.5.4.zip mv apache-maven-3.5.4 /usr/local/maven #解压文件 配置maven国内源 vim /usr/local/maven/conf/settings.xml #159行添加国内源配置 alimaven aliyun maven http://maven.aliyun.com/nexus/content/groups/public/ central 配置jdk编译选项 vim /usr/local/maven/conf/settings.xml # maven 默认使用 jdk1.8 版本，找到&lt;profiles&gt;标签，往其中添加： #253行添加 &lt;profile&gt; &lt;id&gt;jdk8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt; 启动jdk8 vim /usr/local/maven/conf/settings.xml # 275行处添加 &lt;activeProfiles&gt; &lt;activeProfile&gt;jdk8&lt;/activeProfile&gt; &lt;/activeProfiles&gt; 将配置好的jdk和Maven配置到jenkins环境中 [root@jenkins ~]# mv /usr/local/jdk/ data/ [root@jenkins ~]# mv /usr/local/maven/ data/ [root@jenkins ~]# chmod -R 777 data/ 在jenkins全局配置中配置jdk和maven的环境 5.3.2配置Publish 发布&amp;远程操作在系统管理中添加SSH servers配置 六、CI、CD入门操作6.1 持续集成6.1.1 构建任务 选择项目任务 配置git拉取仓库地址保存项目 执行构建任务并检查空调输出构建内容 服务器查看git clone 的代码 #内容存在，证明任务正确,也可以看执行任务的图标 [root@jenkins ~]# ls data/workspace/demoHello/ demoHello.iml pom.xml src 配置mave打包Jar包 重新构建任务，并验证打包结果，这次任务构建时间比较长，需要等待一下 #查看打包任务 [root@jenkins ~]# ls data/workspace/demoHello/target/ classes demoHello-0.0.1.jar demoHello-0.0.1.jar.original generated-sources generated-test-sources maven-archiver maven-status test-classes 配置将生成的Jar包放到目标服务器上，并构建环境 查看工具中Jar包 [root@jenkins ~]# ls /usr/local/test/target/ demoHello-0.0.1.jar 准备Docker构建环境 #docker文件夹结构 $ ls docker/ Dockerfile docker-compose.yml #文件Dockerfile FROM daocloud.io/library/java:8u40-jdk COPY demoHello-0.0.1.jar /usr/local WORKDIR /usr/local CMD java -jar demoHello-0.0.1.jar #docker-compose.yml version: \"3.1\" services: demohello: build: context: ./ dockerfile: Dockerfile image: demohello:v1.0.0 container_name: demohello ports: - 8081:8081 #修改pox.xml demoHello #增加内容，代表项目名称 org.springframework.boot spring-boot-maven-plugin 将项目代码更新gitlab上 $ git add . $ git commit -m \"docker\" $ git push 构建配置环境 构建新的任务，并查看结果 [root@jenkins ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c01978f0cd8c demohello:v1.0.0 \"/bin/sh -c 'java -j…\" 56 seconds ago Up 56 seconds 0.0.0.0:8081->8081/tcp, :::8081->8081/tcp demohello [root@jenkins ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE demohello v1.0.0 478867d8574e 52 minutes ago 846MB #可以通过Linux命令访问部署任务，也可以通过浏览器访问 [root@jenkins docker]# curl http://192.168.75.101:8081/hello Hello World v1.0.1 6.2 持续交付、部署6.2.1 通过标签控制版本信息 配置构建环境 配置gitlab中的tag,首先给目前版本创建tag为v1 更新代码并提交代码修增加tag为v2可以参考上面教程，提交代码和给代码提交版本 #修改docker-compose.yml image: demohello:v2.0.0 #修改src/main/java/com/example/demohello/controller/HelloController.java public String helloWorld() &#123; return \"Hello World v2.0.0\"; &#125; 可以看到构建按钮可以动态选择 执行构建任务并检查结果 [root@jenkins docker]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE demohello v2.0.0 a5158a6c4e1f 22 minutes ago 846MB demohello v1.0.0 9a623fcc1385 23 minutes ago 846MB [root@jenkins docker]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 014179370a24 demohello:v2.0.0 \"/bin/sh -c 'java -j…\" 22 minutes ago Up 22 minutes 0.0.0.0:8081->8081/tcp, :::8081->8081/tcp demohello [root@jenkins docker]# curl http://192.168.75.101:8081/hello Hello World v2.0.0 七、集成Sonar Qube7.1 sonarQube 介绍SonarQube是一个开源的代码质量管理平台，旨在帮助开发团队提高代码的可靠性、可维护性和可扩展性。它提供了一系列的静态代码分析工具，能够自动检测代码中的潜在问题和缺陷，比如代码冗余、代码复杂度、潜在的安全漏洞等。 SonarQube不仅可以对多种编程语言进行分析，如Java、C#、C++、Python等，还支持与各种构建工具和持续集成平台集成，如Maven、Jenkins等。通过在代码开发过程中集成SonarQube，团队可以及早发现和修复潜在的问题，从而提高代码质量和开发效率。 除了代码分析功能，SonarQube还提供了可视化的仪表板和报告，帮助开发团队监控代码质量的趋势和改进的进展。它还支持规则定制和自定义，可以根据团队或项目的特定需求进行配置和扩展。 总的来说，SonarQube是一个功能强大、易于使用的工具，可以帮助开发团队不断提升代码质量，并促进持续的项目成功。 7.2 sonarQube 环境搭建7.2.1 sonarQube 安装 通过docker-compose搭建sonarQube version: \"3.1\" services: db: image: postgres container_name: db ports: - 5432:5432 networks: - sonarnet environment: POSTGRES_USER: sonar POSTGRES_PASSWORD: sonar sonarqube: image: sonarqube:lts-community container_name: sonarqube depends_on: - db ports: - 9000:9000 networks: - sonarnet environment: SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar SONAR_JDBC_USERNAME: sonar SONAR_JDBC_PASSWORD: sonar networks: sonarnet: driver: bridge 当执行docker-compose启动命令，看到sonarQube无法正常启动，修改bug的方法 #查看sonarQube无法启动是否这个原因 [root@jenkins sonarqube_docker]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6e0930750723 sonarqube:lts-community \"bin/run.sh bin/sona…\" 2 minutes ago Exited (0) 2 minutes ago [root@jenkins sonarqube_docker]# docker restart 6e0930750723 |docker logs -f 6e0930750723 ERROR: [1] bootstrap checks failed. You must address the points described in the following [1] lines before starting Elasticsearch. bootstrap check failure [1] of [1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] ERROR: Elasticsearch did not exit normally - check the logs at /opt/sonarqube/logs/sonarqube.log #修改bug,在/etc/sysctl.conf参加vm.max_map_count=262144配置 [root@jenkins sonarqube_docker]# vim /etc/sysctl.conf vm.max_map_count=262144 #使配置生效 [root@jenkins sonarqube_docker]# sysctl -p vm.max_map_count = 262144 #重新启动sonarqube服务器，需要再sonarqube_docker目录 [root@jenkins sonarqube_docker]# docker-compose restart 访问http://192.168.75.101:9000网址，登陆 sonarQube服务,初始化用户名和密码都是admin，服务器启动需要时间，需要耐心等待一会 sonarQube服务汉化，需要安装汉化插件 安装插件需要重新启动服务，需要耐心等待一会 7.2.2 sonarQube 使用7.2.2.1 mave本地使用sonarQube服务 可以通过配置maven，使用sonarQube #在settings.xml配置和配置jdk的位置一样 sonar true admin 123456789 http://192.168.75.101:9000 sonar 在idea的终端输入命令 mvn sonar:sonar 登陆sonarQube查看结果内容 7.2.2.2 sonar-scanner使用sonarQube服务 下载sonar-scanner直接在百度搜索，获取下载地址：https://docs.sonarsource.com/sonarqube/latest/analyzing-source-code/scanners/sonarscanner/ 将sonar-scanner压缩包解压，并配置环境 #解压 [root@jenkins ~]# unzip sonar-scanner-cli-4.8.0.2856-linux.zip #配置环境 [root@jenkins ~]# mv sonar-scanner-cli-4.8.0.2856-linux ./data/sonar-scanner #配置sonar-scanner使用sonarQube的文件 [root@jenkins ~]# vim data/sonar-scanner/conf/sonar-scanner.properties sonar.host.url=http://192.168.75.101:9000 sonar.sourceEncoding=UTF-8 由于sonar-scanner连接sonarQube服务需要秘钥或者用户账号，为了后面的持续集成，我们需要用sonarQube生成一个秘钥给sonar-scanner用 验证sonar-scanner使用sonarQube服务 [root@jenkins ~]# cd data/workspace/demoHello/ [root@jenkins demoHello]# /root/data/sonar-scanner/bin/sonar-scanner -Dsoanr.sources=./ -Dsonar.projectname=demoHello -Dsonar.login=a0277c64b7c5f6c1e03700fdd9f881eb48c98633 -Dsonar.projectKey=demoHello -Dsonar.java.binaries=./target/ …………………… INFO: ------------------------------------------------------------------------ INFO: EXECUTION SUCCESS INFO: ------------------------------------------------------------------------ INFO: Total time: 7.968s INFO: Final Memory: 17M/60M INFO: ------------------------------------------------------------------------ #删除测试生成目录，方便后续为构建jenkins任务排除bug [root@jenkins demoHello]# rm -fr .scannerwork/ 7.2.2.3 Jenkins使用 sonar-scanner配置 需要给Jenkins安装sonarQube插件，我下面的图片是安装好的 配置sonarQube系统环境 安装sonar-scanner 7.2.2.4 任务使用 sonar-scanner配置 执行任务并验证sonar-scanner 八、集成harbor8.1 安装harbor 下载harbor安装包,在github网站上搜索harbor，回去下载链接 wget https://github.com/goharbor/harbor/releases/download/v2.8.2/harbor-offline-installer-v2.8.2.tgz 修改harbor配置文件 #解压harbor tar -xvf harbor-offline-installer-v2.8.2.tgz -C /usr/local #进入harbor目录修改配置文件 cd /usr/local/harbor cp harbor.yml.tmpl harbor.yml vim harbor.yml hostname: 192.168.75.102 #修改服务器IP #https: # # https port for harbor, default is 443 #注释无效配置 # port: 443 # # The path of cert and key files for nginx # certificate: /your/certificate/path # private_key: /your/private/key/path 安装harbor，前提条件是服务器安装了docker和docker-compose #需要耐心等待 bash install.sh …………………… ✔ ----Harbor has been installed and started successfully.---- 验证harbor服务的，服务效果浏览器访问192.168.75.102，默认账号和密码是admin和Harbor12345 创建新仓库名称 镜像上传harbor测试结果 #修改镜像仓库 [root@jenkins ~]# vim /etc/docker/daemon.json &#123; \"insecure-registries\":[\"192.168.11.102:80\"] &#125; #重新启动服务，在这里重新启动镜像后，其他容器需要重新启动 [root@jenkins ~]# systemctl restart docker #给镜像重新打上标签 [root@jenkins ~]# docker tag 2ea870b320a0 192.168.75.102:80/jenkinstest/demohello:v1.0.0 #查看结果 [root@jenkins ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE 192.168.75.102:80/jenkinstest/demohello v1.0.0 2ea870b320a0 17 hours ago 846MB docker login -u admin --password Harbor12345 http://192.168.75.102:80 #登陆harbor仓库 [root@jenkins ~]# docker login -u admin --password Harbor12345 http://192.168.75.102:80 #上传镜像到harbor [root@jenkins ~]# docker push 192.168.75.102:80/jenkinstest/demohello:v1.0.0 The push refers to repository [192.168.75.102:80/jenkinstest/demohello] 登陆harbor查看上传镜像结果 8.2 Jenkins构建镜像推送到harbor 配置Jenkins容器有docker功能 [root@jenkins ~]# cd /var/run/ [root@jenkins run]# ll docker.sock srw-rw---- 1 root docker 0 Jul 13 09:47 docker.sock [root@jenkins run]# chown root:root docker.sock [root@jenkins run]# chmod o+rw docker.sock [root@jenkins run]# ll docker.sock srw-rw-rw- 1 root root 0 Jul 13 09:47 docker.sock #更改关于jenkins的docker-compose文件 version: \"3.1\" services: jenkins: image: jenkins/jenkins:2.413-jdk11 container_name: jenkins ports: - 8080:8080 - 50000:50000 volumes: - ./data/:/var/jenkins_home/ - /var/run/docker.sock:/var/run/docker.sock - /usr/bin/docker:/usr/bin/docker - /etc/docker/daemon.json:/etc/docker/daemon.json #重新启动Jenkins容器 [root@jenkins ~]# docker-compose up -d [+] Running 1/1 ✔ Container jenkins Started #检查Jenkins容器里面是否有docker环境 [root@jenkins ~]# docker exec -it jenkins docker version Client: Docker Engine - Community Version: 24.0.4 …………………… 配置构建任务自动构建镜像并推送到harbor仓库，执行构建任务，并查看harbor仓库 并查看harbor仓库 8.3 服务部署 在目标服务器编写部署代码 [root@jenkins ~]# vim /usr/bin/deploy.sh #!/bin/bash horbar_addr=$1 horbar_repo=$2 project=$3 version=$4 port=$5 imageName=$horbar_addr/$horbar_repo/$project:$version echo $imageName containerId=`docker ps -a |grep $&#123;project&#125;|awk '&#123;print $1&#125;'` echo $containerId if [ \"$containerId\" != \"\" ];then docker stop $containerId docker rm -f $containerId fi tag=`docker images |grep $&#123;project&#125; |awk '&#123;print $2&#125;'` echo $tag if [[ \"$tag\" =~ \"$version\" ]];then docker rmi -f $imageName fi docker login -u admin -p Harbor12345 $horbar_addr docker pull $imageName docker run -d -p $port:$port --name $project $imageName echo \"SUCCESS\" #给脚本赋予执行权限 [root@jenkins ~]# chmod a+x /usr/bin/deploy.sh 修改构建任务信息 九、pipeline 集成构建任务9.1 初识pipeline 创建流水线任务，并测试 执行构建任务 编写Pipeline脚本，构建任务 //所有代码都放到pipeline pipeline &#123; //指定任务在那个集群节点中执行 agent any //声明全局变量，方便后面使用 environment &#123; key = \"value\" &#125; stages &#123; stage('拉取git仓库代码') &#123; steps &#123; echo '拉取git仓库代码 - SUCCESS' &#125; &#125; stage('通过maven构建项目') &#123; steps &#123; echo '通过maven构建项目 - SUCCESS' &#125; &#125; stage('通过SonarQube做代码质量检查') &#123; steps &#123; echo '通过SonarQube做代码质量检查 - SUCCESS' &#125; &#125; stage('通过Docker制作自定义镜像') &#123; steps &#123; echo '通过Docker制作自定义镜像 - SUCCESS' &#125; &#125; stage('将自定义镜像推送到Harbor') &#123; steps &#123; echo '将自定义镜像推送到Harbor - SUCCESS' &#125; &#125; stage('通过Publish Over SSH通知目标服务器') &#123; steps &#123; echo '通过Publish Over SSH通知目标服务器 - SUCCESS' &#125; &#125; &#125; &#125; pipeline 集成构建任务编写语法 9.2 编写项目中的pipeline脚本 本项目使用scm编写pipeline文件 在gitlab创建Jenkinsfile 配置jenkins邮箱服务 //所有代码都放到pipeline pipeline &#123; //指定任务在那个集群节点中执行 agent any //声明全局变量，方便后面使用 environment &#123; harborUser = 'admin' harborPasswd = 'Harbor12345' harborAddress = '192.168.75.102:80' harborRepo = 'jenkinstest' &#125; stages &#123; stage('拉取git仓库代码') &#123; steps &#123; checkout scmGit(branches: [[name: '$&#123;tag&#125;']], extensions: [], userRemoteConfigs: [[url: 'http://192.168.75.100:8929/root/demoHello.git']]) &#125; &#125; stage('通过maven构建项目') &#123; steps &#123; sh '/var/jenkins_home/maven/bin/mvn clean package -DskipTests' echo '通过maven构建项目 - SUCCESS' &#125; &#125; stage('通过SonarQube做代码质量检查') &#123; steps &#123; sh '/var/jenkins_home/sonar-scanner/bin/sonar-scanner -Dsonar.projectname=$&#123;JOB_NAME&#125; -Dsonar.projectKey=$&#123;JOB_NAME&#125; -Dsonar.source=./ -Dsonar.java.binaries=target -Dsonar.login=a0277c64b7c5f6c1e03700fdd9f881eb48c98633' echo '通过SonarQube做代码质量检查 - SUCCESS' &#125; &#125; stage('通过Docker制作自定义镜像') &#123; steps &#123; sh '''mv ./target/*.jar docker/ docker build -t 192.168.75.102:80/jenkinstest/$&#123;JOB_NAME&#125;:$tag docker/ docker image prune -f''' &#125; &#125; stage('将自定义镜像推送到Harbor') &#123; steps &#123; sh '''docker login -u $&#123;harborUser&#125; -p $&#123;harborPasswd&#125; $&#123;harborAddress&#125; docker push $&#123;harborAddress&#125;/$&#123;harborRepo&#125;/$&#123;JOB_NAME&#125;:$tag''' &#125; &#125; stage('通过Publish Over SSH通知目标服务器') &#123; steps &#123; //这边有个坑，默认生成的脚步命令是单引号需要改成双引号 sshPublisher(publishers: [sshPublisherDesc(configName: 'test', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: \"deploy.sh $&#123;harborAddress&#125; $&#123;harborRepo&#125; $&#123;JOB_NAME&#125; $tag $port\", execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: true)]) &#125; &#125; &#125; //需要配置jenkin邮箱服务 post&#123; success &#123; emailext body: '构建成功', subject: '构建成功', to: '1626395559@qq.com' &#125; failure&#123; emailext body: '构建失败', subject: '构建失败', to: '1626395559@qq.com' &#125; &#125; &#125;","categories":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skillixx.com/tags/Linux/"},{"name":"云计算","slug":"云计算","permalink":"https://skillixx.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://skillixx.com/tags/Jenkins/"}],"keywords":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"磁盘优化工具spacesniffer","slug":"spacesniffer","date":"2023-06-09T08:27:02.000Z","updated":"2023-06-09T08:41:00.789Z","comments":true,"path":"9a299a77.html","link":"","permalink":"https://skillixx.com/9a299a77.html","excerpt":"","text":"SpaceSniffer是一款免费的磁盘空间分析工具，它可以帮助用户快速了解磁盘上的文件和文件夹占用空间情况，方便用户进行磁盘清理和优化。 界面简介SpaceSniffer的界面非常直观，它会以图形化的方式展示磁盘上的文件和文件夹。用户可以通过缩放和移动来查看不同层级的文件夹和文件，同时还可以通过颜色区分不同类型的文件和文件夹。 高级功能除了基本的文件大小和占用空间信息外，SpaceSniffer还提供了一些高级功能，比如可以按照文件类型、修改时间、访问时间等进行排序，还可以通过过滤器来快速查找指定类型的文件。 总结总的来说，SpaceSniffer是一款非常实用的磁盘工具，它可以帮助用户快速了解磁盘上的文件和文件夹占用空间情况，方便用户进行磁盘清理和优化。如果你需要对磁盘空间进行管理，SpaceSniffer是一个不错的选择。 下载地址https://wwst.lanzout.com/iJeaE0yp1cxg","categories":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"系统优化","slug":"系统优化","permalink":"https://skillixx.com/tags/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/"},{"name":"window","slug":"window","permalink":"https://skillixx.com/tags/window/"}],"keywords":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"DNS入门搭建","slug":"createdns","date":"2023-06-09T07:58:51.000Z","updated":"2023-06-09T09:39:13.181Z","comments":true,"path":"ab2c4f2.html","link":"","permalink":"https://skillixx.com/ab2c4f2.html","excerpt":"","text":"一、环境介绍配置根据自己的电脑配置，设置 系统说明 服务器&#x2F;Linux 测试客户端win 系统版本 Centos7.8 window10专业版 配置 2G,4cpu 4G,2 vcpu 二、配置搭建环境1.配置网络镜像源 //备份镜像源 [root@xiaozhang ~]# mv /etc/yum.repos.d/CentOS-* /opt/ //下载阿里云网络镜像源 [root@xiaozhang ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo //清除缓存安装包 [root@xiaozhang ~]# yum clena all //刷新网络镜像源 [root@xiaozhang ~]# yum repolist 2.检查是否关闭Selinux 检查关闭，如果没有关闭，请关闭Selinx [root@xiaozhang ~]# getenforce Disabled 如何关闭Selinux //更改配置文件 [root@xiaozhang ~]# sed -i \"s/SELINUX=enforcing/SELINUX=disabled/g\" /etc/selinux/config //关机重启 [root@xiaozhang ~]# reboot 3.放行DNS端口53 //查看防火墙是否启动 [root@xiaozhang ~]# firewall-cmd --state running //如果不是防火墙没有启动，无需执行下面的的命令 [root@xiaozhang ~]# firewall-cmd --zone=public --add-port=53/tcp --permanent success [root@xiaozhang ~]# firewall-cmd --zone=public --add-port=53/udp --permanent success [root@xiaozhang ~]# firewall-cmd --reload success [root@xiaozhang ~]# firewall-cmd --zone=public --list-ports 53/tcp 53/udp 三、搭建DNS服务1.安装DNS软件 [root@xiaozhang ~]# yum install bind-* -y 2.配置文件修改 //打开文件/etc/named.conf vim /etc/named.conf options &#123; listen-on port 53 &#123; any; &#125;; //更改了监听的IP地址，any表示允许任何IP地址连接 listen-on-v6 port 53 &#123; ::1; &#125;; directory \"/var/named\"; dump-file \"/var/named/data/cache_dump.db\"; statistics-file \"/var/named/data/named_stats.txt\"; memstatistics-file \"/var/named/data/named_mem_stats.txt\"; recursing-file \"/var/named/data/named.recursing\"; secroots-file \"/var/named/data/named.secroots\"; allow-query &#123; any; &#125;; //更改了允许查询的IP地址，any表示允许任何IP地址查询 recursion yes; //开启了递归查询 forwarders &#123; 114.114.114.114; 223.5.5.5; &#125;; //增加转发域名DNS服务器 dnssec-enable no; //禁用了DNSSEC功能 dnssec-validation no; //禁用了DNSSEC验证 /* Path to ISC DLV key */ bindkeys-file \"/etc/named.root.key\"; managed-keys-directory \"/var/named/dynamic\"; pid-file \"/run/named/named.pid\"; session-keyfile \"/run/named/session.key\"; &#125;; logging &#123; channel default_debug &#123; file \"data/named.run\"; severity dynamic; &#125;; &#125;; zone \".\" IN &#123; type hint; file \"named.ca\"; &#125;; include \"/etc/named.rfc1912.zones\"; include \"/etc/named.root.key\"; 3.配置解析的域名 解析域名 vim /etc/named.rfc1912.zones …… //正向解析 zone \"skillzhang.com\" IN &#123; type master; file \"skillzhang.com.zone\"; allow-update &#123; none; &#125;; &#125;; //反向解析 zone \"127.168.192.in-addr.arpa\" IN &#123; type master; file \"192.168.127.arpa\"; allow-update &#123; none; &#125;; &#125;; //正向解析文件 vim skillzhang.com.zone $TTL 1D @ IN SOA @ rname.invalid. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS @ A 192.168.127.100 www IN A 192.168.127.100 //反向解析文件 vim 192.168.127.arpa $TTL 1D @ IN SOA skillzhang.com. root ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum NS skillzhang.com. A 192.168.127.100 100 IN PTR skillzhang.com. //100为ip地址 //启动DNS服务 [root@xiaozhang named]# systemctl restart named [root@xiaozhang named]# systemctl enable named Created symlink from /etc/systemd/system/multi-user.target.wants/named.service to /usr/lib/systemd/system/named.service. 四、检查验证服务1.Linux系统测试验证 替换本地DNS服务器地址 //修改本地DNS [root@xiaozhang named]# vim /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=ens33 UUID=94092393-3b2d-40c4-ac97-e406ba043ad9 DEVICE=ens33 ONBOOT=yes IPADDR=192.168.127.100 PREFIX=24 GATEWAY=192.168.127.2 DNS1=192.168.127.100 //修改 IPV6_PRIVACY=no ZONE=public //重新启动网络 [root@xiaozhang ~]# systemctl restart network 验证DNS服务解析 [root@xiaozhang named]# nslookup //检查命令 &gt; killbobo.com //域名正向解析检查 Server: 192.168.127.100 Address: 192.168.127.100#53 ** server can&#39;t find killbobo.com: NXDOMAIN &gt; 192.168.127.100 //域名反向解析检查 100.127.168.192.in-addr.arpa name = skillzhang.com. &gt; baidu.com //域名缓存检查 Server: 192.168.127.100 Address: 192.168.127.100#53 Non-authoritative answer: Name: baidu.com Address: 39.156.66.10 Name: baidu.com Address: 110.242.68.66 2.Window系统验证 更改DNS配置 验证DNS服务，打开命令行窗口","categories":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skillixx.com/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://skillixx.com/tags/%E7%BD%91%E7%BB%9C/"},{"name":"DNS","slug":"DNS","permalink":"https://skillixx.com/tags/DNS/"},{"name":"window","slug":"window","permalink":"https://skillixx.com/tags/window/"}],"keywords":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"Podman入门","slug":"podman","date":"2023-06-06T02:22:50.000Z","updated":"2023-06-06T02:45:00.090Z","comments":false,"path":"336e2b35.html","link":"","permalink":"https://skillixx.com/336e2b35.html","excerpt":"","text":"podman vs docker什么是Podman？ Podman 是一个开源的容器运行时项目，可在大多数 Linux 平台上使用。Podman 提供与 Docker 非常相似的功能。正如前面提到的那样，它不需要在你的系统上运行任何守护进程，并且它也可以在没有 root 权限的情况下运行。 Podman 可以管理和运行任何符合 OCI（Open Container Initiative）规范的容器和容器镜像。Podman 提供了一个与 Docker 兼容的命令行前端来管理 Docker 镜像。 Podman 官网地址：https://podman.io/ Podman和Docker的主要区别是什么？ dockers在实现CRI的时候，它需要一个守护进程，其次需要以root运行，因此这也带来了安全隐患。 podman不需要守护程序，也不需要root用户运行，从逻辑架构上，比docker更加合理。 在docker的运行体系中，需要多个daemon才能调用到OCI的实现RunC。 在容器管理的链路中，Docker Engine的实现就是dockerd daemon，它在linux中需要以root运行，dockerd调用containerd，containerd调用containerd-shim，然后才能调用runC。顾名思义shim起的作用也就是“垫片”，避免父进程退出影响容器的运训 podman直接调用OCI,runtime（runC），通过common作为容器进程的管理工具，但不需要dockerd这种以root身份运行的守护进程。 在podman体系中，有个称之为common的守护进程，其运行路径通常是&#x2F;usr&#x2F;libexec&#x2F;podman&#x2F;conmon，它是各个容器进程的父进程，每个容器各有一个，common的父则通常是1号进程。podman中的common其实相当于docker体系中的containerd-shim。 图中所体现的事情是，podman不需要守护进程，而dorker需要守护进程。在这个图的示意中，dorcker的containerd-shim与podman的common被归在Container一层。 Podman的使用与docker有什么区别？podman的定位也是与docker兼容，因此在使用上面尽量靠近docker。在使用方面，可以分成两个方面来说，一是系统构建者的角度，二是使用者的角度。 在系统构建者方面，用podman的默认软件，与docker的区别不大，只是在进程模型、进程关系方面有所区别。如果习惯了docker几个关联进程的调试方法，在podman中则需要适应。可以通过pstree命令查看进程的树状结构。总体来看，podman比docker要简单。由于podman比docker少了一层daemon，因此重启的机制也就不同了。 在使用者方面，podman与docker的命令基本兼容，都包括容器运行时（run&#x2F;start&#x2F;kill&#x2F;ps&#x2F;inspect），本地镜像（images&#x2F;rmi&#x2F;build）、镜像仓库（login&#x2F;pull&#x2F;push）等几个方面。因此podman的命令行工具与docker类似，比如构建镜像、启停容器等。甚至可以通过alias docker&#x3D;podman可以进行替换。因此，即便使用了podman，仍然可以使用docker.io作为镜像仓库，这也是兼容性最关键的部分。 Podman常用命令容器podman run 创建并启动容器 podman start 启动容器 podman ps 查看容器 podman stop 终止容器 podman restart 重启容器 podman attach 进入容器 podman exec 进入容器 podman export 导出容器 podman import 导入容器快照 podman rm 删除容器 podman logs 查看日志 镜像podman search 检索镜像 podman pull 获取镜像 podman images 列出镜像 podman image Is 列出镜像 podman rmi 删除镜像 podman image rm 删除镜像 podman save 导出镜像 podman load 导入镜像 podmanfile 定制镜像（三个） podman build 构建镜像 podman run 运行镜像 podmanfile 常用指令（四个） COPY 复制文件 ADD 高级复制 CMD 容器启动命令 ENV 环境变量 EXPOSE 暴露端口 部署 Podman//安装podman [root@localhost ~]# yum -y install podman Podman 加速器版本7配置加速器 //仓库配置 [root@localhost ~]*# vim /etc/containers/registries.conf* [registries.search] *#registries = [\"registry.access.redhat.com\", \"registry.redhat.io\", \"docker.io\"] #这个是查找，从这三个地方查找* registries = [\"docker.io\"] *#如果只留一个，则只在一个源里查找* [[docker.io]] location=\"j3m2itm3.mirror.aliyuncs.com\" 版本8配置加速器 *#unqualified-search-registries = [\"registry.fedoraproject.org\", \"registry.access.redhat.com\", \"registry.centos.org\", \"docker.io\"] #直接注释掉* unqualified-search-registries = [\"docker.io\"] *#添加一个docker.io* [[registry]] prefix = \"docker.io\" location = \"j3m2itm3.mirror.aliyuncs.com\" （不用加https:// 直接加地址） ### **使用 Podman** 使用 Podman 非常的简单，Podman 的指令跟 Docker 大多数都是相同的。下面我们来看几个常用的例子： 运行一个容器 [root@localhost ~]# podman run -d --name httpd docker.io/library/httpd Trying to pull docker.io/library/httpd... Getting image source signatures Copying blob e5ae68f74026 done Copying blob d3576f2b6317 done Copying blob bc36ee1127ec done Copying blob f1aa5f54b226 done Copying blob aa379c0cedc2 done Copying config ea28e1b82f done Writing manifest to image destination Storing signatures 0492e405b9ecb05e6e6be1fec0ac1a8b6ba3ff949df259b45146037b5f355035 //查看镜像 [root@localhost ~]# podman images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/library/httpd latest ea28e1b82f31 11 days ago 148 MB 列出运行的容器 [root@localhost ~]# podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0492e405b9ec docker.io/library/httpd:latest httpd-foreground About a minute ago Up About a minute ago httpd 注意：如果在ps命令中添加-a，Podman 将显示所有容器。 检查正在运行的容器 您可以“检查”正在运行的容器的元数据和有关其自身的详细信息。我们甚至可以使用 inspect 子命令查看分配给容器的 IP 地址。由于容器以无根模式运行，因此未分配 IP 地址，并且该值将在检查的输出中列为“无”。 [root@localhost ~]# podman inspect -l | grep IPAddress\\\": \"SecondaryIPAddresses\": null, \"IPAddress\": \"10.88.0.5\", [root@localhost ~]# curl 10.88.0.5 It works! 注意：-l 是最新容器的便利参数。您还可以使用容器的 ID 代替 -l。 查看一个运行中容器的日志 选项 --latest #最近的 [root@localhost ~]# podman logs --latest AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.88.0.5. Set the 'ServerName' directive globally to suppress this message AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.88.0.5. Set the 'ServerName' directive globally to suppress this message [Mon Dec 13 15:17:53.690844 2021] [mpm_event:notice] [pid 1:tid 140665160166720] AH00489: Apache/2.4.51 (Unix) configured -- resuming normal operations [Mon Dec 13 15:17:53.690946 2021] [core:notice] [pid 1:tid 140665160166720] AH00094: Command line: 'httpd -D FOREGROUND' 10.88.0.1 - - [13/Dec/2021:15:19:48 +0000] \"GET / HTTP/1.1\" 200 45 10.88.0.1 - - [13/Dec/2021:15:20:47 +0000] \"GET / HTTP/1.1\" 200 45 查看一个运行容器中的进程资源使用情况，可以使用top观察容器中的 nginx pid 语法： podman top [root@localhost ~]# podman top httpd USER PID PPID %CPU ELAPSED TTY TIME COMMAND root 1 0 0.000 15m38.599711321s ? 0s httpd -DFOREGROUND www-data 7 1 0.000 15m38.599783256s ? 0s httpd -DFOREGROUND www-data 8 1 0.000 15m38.599845342s ? 0s httpd -DFOREGROUND www-data 9 1 0.000 15m38.599880444s ? 0s httpd -DFOREGROUND 停止一个运行中的容器 [root@localhost ~]# podman stop --latest 2f3edf712621d3a41e03fa8c7f6a5cdba56fbbad43a7a59ede26cc88f31006c4 [root@localhost ~]# podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 删除一个容器 [root@localhost ~]# podman rm --latest 2f3edf712621d3a41e03fa8c7f6a5cdba56fbbad43a7a59ede26cc88f31006c4 [root@localhost ~]# podman ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 以上这些特性基本上都和 Docker 一样，Podman 除了兼容这些特性外，还支持了一些新的特性。 上传镜像 例如，如果我们想在 docker.io 上分享我们新建的 Nginx 容器镜像，这很容易。首先登录码头： [root@localhost nginx]# tree . ├── Dockerfile └── files └── nginx-1.20.1.tar.gz [root@localhost nginx]# cat Dockerfile FROM docker.io/library/centos ENV PATH /usr/local/nginx/sbin:$PATH ADD files/nginx-1.20.1.tar.gz /usr/src RUN useradd -r -M -s /sbin/nologin nginx && \\ yum -y install pcre-devel openssl openssl-devel gd-devel gcc gcc-c++ make && \\ mkdir -p /var/log/nginx && \\ cd /usr/src/nginx-1.20.1 && \\ ./configure \\ --prefix=/usr/local/nginx \\ --user=nginx \\ --group=nginx \\ --with-debug \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_image_filter_module \\ --with-http_gunzip_module \\ --with-http_gzip_static_module \\ --with-http_stub_status_module \\ --http-log-path=/var/log/nginx/access.log \\ --error-log-path=/var/log/nginx/error.log && \\ make && make install CMD [\"nginx\",\"-g\",\"daemon off\"] [root@localhost nginx]# podman build -t nginx . // 修改镜像名 [root@localhost ~]# podman tag docker.io/library/nginx:latest docker.io/1314444/test:latest // 登录并上传镜像 [root@localhost ~]# podman login docker.io // 需要告诉其要登录到docker仓库 [root@localhost ~]# podman login docker.io Username: 1314444 #账户 Password: ******** #密码 Login Succeeded! [root@localhost nginx]# podman push docker.io/1314444/test:latest //上传镜像 Getting image source signatures Copying blob 38c40d6c2c85 done Copying blob fee76a531659 done Copying blob c2adabaecedb done Copying config 7f3589c0b8 done Writing manifest to image destination Copying config 7f3589c0b8 done Writing manifest to image destination Storing signatures //请注意，我们将四层推送到我们的注册表，现在可供其他人共享。快速浏览一下： [root@localhost ~]# podman inspect 1314444/test:nginx //输出： [ &#123; \"Id\": \"7f3589c0b8849a9e1ff52ceb0fcea2390e2731db9d1a7358c2f5fad216a48263\", \"Digest\": \"sha256:7822b5ba4c2eaabdd0ff3812277cfafa8a25527d1e234be028ed381a43ad5498\", \"RepoTags\": [ \"docker.io/1314444/test:nginx\", ...... 总而言之，Podman 使查找、运行、构建和共享容器变得容易。 配置别名 如果习惯了使用 Docker 命令，可以直接给 Podman 配置一个别名来实现无缝转移。你只需要在 .bashrc 下加入以下行内容即可： [root@localhost ~]# echo \"alias docker=podman\" >> .bashrc source .bashrc [root@localhost ~]# alias alias cp='cp -i' alias docker='podman' ....... 用户操作在允许没有root特权的用户运行Podman之前，管理员必须安装或构建Podman并完成以下配置 cgroup V2Linux内核功能允许用户限制普通用户容器可以使用的资源，如果使用cgroupV2启用了运行Podman的Linux发行版，则可能需要更改默认的OCI运行时。某些较旧的版本runc不适用于cgroupV2，必须切换到备用OCI运行时crun。 [root@localhost ~]# yum -y install crun //centos8系统自带 [root@localhost ~]# vi /usr/share/containers/containers.conf 446 # Default OCI runtime 447 # 448 runtime = \"crun\" //取消注释并将runc改为crun [root@localhost ~]# podman run -d --name web -p 80:80 docker.io/library/nginx c8664d2e43c872e1e5219f82d41f63048ed3a5ed4fb6259c225a14d6c243677f [root@localhost ~]# podman inspect web | grep crun \"OCIRuntime\": \"crun\", \"crun\", 安装slirp4netns和fuse-overlayfs 在普通用户环境中使用Podman时，建议使用fuse-overlayfs而不是VFS文件系统，至少需要版本0.7.6。现在新版本默认就是了。 [root@localhost ~]# yum -y install slirp4netns [root@localhost ~]# yum -y install fuse-overlayfs [root@localhost ~]# vi /etc/containers/storage.conf 77 mount_program = \"/usr/bin/fuse-overlayfs\" //取消注释 &#x2F; etc &#x2F; subuid和&#x2F; etc &#x2F; subgid配置 Podman要求运行它的用户在&#x2F; etc &#x2F; subuid和&#x2F; etc &#x2F; subgid文件中列出一系列UID,shadow-utils或newuid包提供这些文件 [root@localhost ~]# yum -y install shadow-utils 可以在/ etc / subuid和/ etc / subgid查看，每个用户的值必须唯一且没有任何重叠。 [root@localhost ~]# useradd zz [root@localhost ~]# cat /etc/subuid zz:100000:65536 [root@localhost ~]# cat /etc/subgid zz:100000:65536 // 启动非特权ping [root@localhost ~]# sysctl -w \"net.ipv4.ping_group_range=0 200000\" //大于100000这个就表示tom可以操作podman net.ipv4.ping_group_range = 0 200000 这个文件的格式是 USERNAME:UID:RANGE中&#x2F;etc&#x2F;passwd或输出中列出的用户名getpwent。 为用户分配的初始 UID。 为用户分配的 UID 范围的大小。 该usermod程序可用于为用户分配 UID 和 GID，而不是直接更新文件。 [root@localhost ~]# usermod --add-subuids 200000-201000 --add-subgids 200000-201000 hh grep hh /etc/subuid /etc/subgid /etc/subuid:hh:200000:1001 /etc/subgid:hh:200000:1001 用户配置文件 三个主要的配置文件是container.conf 、storage.conf 和r egistries.conf 。用户可以根据需要修改这些文件。 container.conf // 用户配置文件 [root@localhost ~]*# cat /usr/share/containers/containers.conf* [root@localhost ~]*# cat /etc/containers/containers.conf* [root@localhost ~]*# cat ~/.config/containers/containers.conf //优先级最高* 如果它们以该顺序存在。每个文件都可以覆盖特定字段的前一个文件。 配置storage.conf文件 1./etc/containers/storage.conf 2.$HOME/.config/containers/storage.conf 在普通用户中**&#x2F;etc&#x2F;containers&#x2F;storage.conf** 的一些字段将被忽略 [root@localhost ~]# vi /etc/containers/storage.conf [storage] > 推荐下自己做的 Spring Cloud 的实战项目： > > # Default Storage Driver, Must be set for proper operation. driver = \"overlay\" #此处改为overlay ....... mount_program = \"/usr/bin/fuse-overlayfs\" #取消注释 [root@localhost ~]# sysctl user.max_user_namespaces=15000 #如果版本为8以下，则需要做以下操作： 在普通用户中这些字段默认 graphroot=\"$HOME/.local/share/containers/storage\" runroot=\"$XDG_RUNTIME_DIR/containers\" registries.conf 配置按此顺序读入,这些文件不是默认创建的,可以从&#x2F;usr&#x2F;share&#x2F;containers 或复制文件&#x2F;etc&#x2F;containers并进行修改。 1./etc/containers/registries.conf 2./etc/containers/registries.d/* 3.HOME/.config/containers/registries.conf 授权文件 此文件里面写了docker账号的密码，以加密方式显示 [root@localhost ~]# podman login Username: 1314444 Password: Login Succeeded! [root@localhost ~]# cat /run/user/0/containers/auth.json &#123; \"auths\": &#123; \"registry.fedoraproject.org\": &#123; \"auth\": \"MTMxNDQ0NDpIMjAxNy0xOA==\" &#125; &#125; &#125; 普通用户是无法看见root用户的镜像的 //root用户 [root@localhost ~]# podman images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/library/httpd latest ea28e1b82f31 11 days ago 146 MB //普通用户 [root@localhost ~]# su - zz [zz@localhost ~]$ podman images REPOSITORY TAG IMAGE ID CREATED SIZE 卷 容器与root用户一起运行，则root容器中的用户实际上就是主机上的用户。 UID GID是在&#x2F;etc&#x2F;subuid和&#x2F;etc&#x2F;subgid等中用户映射中指定的第一个UID GID。 如果普通用户的身份从主机目录挂载到容器中，并在该目录中以根用户身份创建文件，则会看到它实际上是你的用户在主机上拥有的。 使用卷 [root@localhost ~]# su - zz [zz@localhost ~]$ pwd /home/zz [zz@localhost ~]$ mkdir /home/zz/data [zz@localhost ~]$ podman run -it -v \"$(pwd)\"/data:/data docker.io/library/busybox /bin/sh Trying to pull docker.io/library/busybox:latest... Getting image source signatures Copying blob 3cb635b06aa2 done Copying config ffe9d497c3 done Writing manifest to image destination Storing signatures / # ls bin data dev etc home proc root run sys tmp usr var / # cd data/ /data # ls /data # touch 123 /data # ls -l total 0 -rw-r--r-- 1 root root 0 Dec 13 00:17 123 在主机上查看 [zz@localhost ~]$ ll data/ 总用量 0 -rw-r--r-- 1 zz zz 0 12月 13 00:17 123 //写入文件 [zz@localhost ~]$ echo \"hell world\" >> 123 [zz@localhost ~]$ cat 123 hell world 容器里查看 /data # cat 123 hell world //我们可以发现在容器里面的文件的属主和属组都属于root，那么如何才能让其属于tom用户呢？下面告诉你答案 /data # ls -l total 4 -rw-rw-r-- 1 root root 12 Dec 13 00:20 123 //只要在运行容器的时候加上一个--userns=keep-id即可。 [zz@localhost ~]$ podman run -it --name test -v \"$(pwd)\"/data:/data --userns=keep-id docker.io/library/busybox /bin/sh ~ $ cd data/ /data $ ls -l total 4 -rw-r--r-- 1 zz zz 11 Dec 13 00:21 123 使用普通用户映射容器端口时会报“ permission denied”的错误 [zz@localhost ~]$ podman run -d -p 80:80 httpd Error: rootlessport cannot expose privileged port 80, you can add 'net.ipv4.ip_unprivileged_port_start=80' to /etc/sysctl.conf (currently 1024), or choose a larger port number (>= 1024): listen tcp 0.0.0.0:80: bind: permission denied 普通用户可以映射&gt;&#x3D; 1024的端口 [zz@localhost ~]$ podman run -d -p 1024:80 httpd 58613a6bdc70d4d4f9f624583f795a62a610596d166f0873bdff8fb26aa15092 [zz@localhost ~]$ ss -anlt State Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 128 *:1024 *:* LISTEN 0 128 [::]:22 [::]:* 配置echo ‘net.ipv4.ip_unprivileged_port_start&#x3D;80’ &gt;&gt; &#x2F;etc&#x2F;sysctl.conf后可以映射大于等于80的端口 [root@localhost ~]# echo 'net.ipv4.ip_unprivileged_port_start=80' >> /etc/sysctl.conf [root@localhost ~]# sysctl -p net.ipv4.ip_unprivileged_port_start = 80 [zz@localhost ~]$ podman run -d -p 80:80 httpd 1215455a0c300d78e7bf6afaefc9873f818c6b0f26affeee4e2bc17954e72d8e [zz@localhost ~]$ ss -anlt State Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 128 *:1024 *:* LISTEN 0 128 *:80 *:* LISTEN 0 128 [::]:22 [::]:* 网络Podman网络操作与Docker类似，但也有一些不同之处。以下是一些常见的Podman网络操作： 创建网络：可以使用podman network create命令创建一个新的网络。例如，创建一个名为my-network的桥接网络： podman network create my-network --driver bridge 查看网络：可以使用podman network ls命令查看所有可用的网络。 连接容器到网络：可以使用--network选项将容器连接到指定的网络。例如，将名为my-container的容器连接到my-network网络： podman run --name my-container --network my-network -d my-image 断开容器与网络的连接：可以使用podman network disconnect命令将容器与网络断开连接。例如，将名为my-container的容器与my-network网络断开连接： podman network disconnect my-network my-container 删除网络：可以使用podman network rm命令删除指定的网络。例如，删除名为my-network的网络： podman network rm my-network 这些是一些常见的Podman网络操作，您可以根据您的具体需求和环境来使用它们。","categories":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skillixx.com/tags/Linux/"},{"name":"Podman","slug":"Podman","permalink":"https://skillixx.com/tags/Podman/"},{"name":"Docker","slug":"Docker","permalink":"https://skillixx.com/tags/Docker/"}],"keywords":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"区分机械、固态和M2","slug":"disk","date":"2023-05-16T02:45:56.000Z","updated":"2023-05-16T02:59:53.621Z","comments":false,"path":"c74dd02.html","link":"","permalink":"https://skillixx.com/c74dd02.html","excerpt":"","text":"如何快速从型号上鉴别电脑硬盘是机械、固态和M2 机械硬盘：机械硬盘的型号通常以“HDD”（Hard Disk Drive）结尾，例如“Seagate Barracuda 2TB HDD”。 固态硬盘： 固态硬盘的型号通常以“SSD”（Solid State Drive）结尾，例如“Samsung 860 EVO 1TB SSD”。 M2硬盘： M2硬盘的型号通常以“M.2”结尾，例如“WD Blue 1TB M.2 2280 Internal SSD”。 通过硬盘型号的后缀，可以快速鉴别电脑硬盘是机械、固态还是M2硬盘。","categories":[{"name":"IT科技","slug":"IT科技","permalink":"https://skillixx.com/categories/IT%E7%A7%91%E6%8A%80/"}],"tags":[{"name":"电脑硬件","slug":"电脑硬件","permalink":"https://skillixx.com/tags/%E7%94%B5%E8%84%91%E7%A1%AC%E4%BB%B6/"},{"name":"系统优化","slug":"系统优化","permalink":"https://skillixx.com/tags/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/"}],"keywords":[{"name":"IT科技","slug":"IT科技","permalink":"https://skillixx.com/categories/IT%E7%A7%91%E6%8A%80/"}]},{"title":"电脑优化的方法","slug":"systemopt","date":"2023-05-16T02:33:36.000Z","updated":"2023-05-16T02:40:08.672Z","comments":false,"path":"85378675.html","link":"","permalink":"https://skillixx.com/85378675.html","excerpt":"","text":"电脑卡的原因和优化方法电脑卡的原因可能有很多，比如系统过于老旧、软件冲突、病毒感染等等。以下是一些电脑优化的基本方法： 清理垃圾文件：使用系统自带的磁盘清理工具或第三方清理软件，清理系统中的垃圾文件，释放硬盘空间。 卸载不必要的软件：卸载不常用或不必要的软件，减少系统负担。 更新系统和驱动程序：更新系统和驱动程序可以修复一些已知的问题和漏洞，提高系统的稳定性和性能。 关闭不必要的启动项：在系统启动时，关闭不必要的启动项，减少系统启动时间和资源占用。 安装杀毒软件：安装杀毒软件可以保护系统免受病毒和恶意软件的攻击，提高系统的安全性和稳定性。 清理注册表：使用注册表清理工具清理系统中的无效注册表项，提高系统的稳定性和性能。 增加内存：如果电脑配置较低，可以考虑增加内存，提高系统的运行速度和稳定性。 优化硬盘：使用硬盘优化工具对硬盘进行优化，提高硬盘读写速度和稳定性。 关闭特效：关闭系统特效可以减少系统资源占用，提高系统的运行速度和稳定性。 定期清理系统：定期清理系统中的临时文件、缓存文件等，保持系统的清洁和稳定。","categories":[{"name":"IT科技","slug":"IT科技","permalink":"https://skillixx.com/categories/IT%E7%A7%91%E6%8A%80/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skillixx.com/tags/Linux/"},{"name":"系统优化","slug":"系统优化","permalink":"https://skillixx.com/tags/%E7%B3%BB%E7%BB%9F%E4%BC%98%E5%8C%96/"},{"name":"Window","slug":"Window","permalink":"https://skillixx.com/tags/Window/"}],"keywords":[{"name":"IT科技","slug":"IT科技","permalink":"https://skillixx.com/categories/IT%E7%A7%91%E6%8A%80/"}]},{"title":"Python基础环境安装教程","slug":"pythoninstall","date":"2023-05-10T03:07:11.000Z","updated":"2023-05-10T06:09:32.790Z","comments":false,"path":"74b57a6d.html","link":"","permalink":"https://skillixx.com/74b57a6d.html","excerpt":"","text":"好的，以下是使用Markdown方式写Python环境安装和Pycharm环境安装的教程，并附带图片，图片也使用Markdown方式进行显示。 Python环境安装和Pycharm环境安装Python环境安装 打开Python官网：https://www.python.org/downloads/ 在下载页面中，选择适合你操作系统的Python版本，点击下载。 下载完成后，双击安装程序，按照提示进行安装。 在安装过程中，记得勾选“Add Python to PATH”选项，这样可以方便在命令行中使用Python。 安装完成后，打开命令行，输入python，如果出现以下信息，则说明Python环境已经安装成功。Python 3.9.0 (tags/v3.9.0:9cf6752, Oct 5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)] on win32 Pycharm环境安装 打开Pycharm官网：https://www.jetbrains.com/pycharm/download/ 在下载页面中，选择适合你操作系统的Pycharm版本，点击下载。 下载完成后，双击安装程序，按照提示进行安装。 在安装过程中，可以选择安装的组件，也可以使用默认设置。 安装完成后，打开Pycharm，选择创建一个新项目，或者打开一个已有的项目。 至此，Python环境和Pycharm环境已经安装完成。可以开始愉快的Python编程啦！","categories":[{"name":"编程教程","slug":"编程教程","permalink":"https://skillixx.com/categories/%E7%BC%96%E7%A8%8B%E6%95%99%E7%A8%8B/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://skillixx.com/tags/Python/"}],"keywords":[{"name":"编程教程","slug":"编程教程","permalink":"https://skillixx.com/categories/%E7%BC%96%E7%A8%8B%E6%95%99%E7%A8%8B/"}]},{"title":"小爱音箱智能家居控制","slug":"xiaoai","date":"2023-05-10T02:51:50.000Z","updated":"2023-05-10T03:02:25.479Z","comments":false,"path":"4a08a452.html","link":"","permalink":"https://skillixx.com/4a08a452.html","excerpt":"","text":"小爱音箱是一款智能音箱，可以通过语音控制智能家居设备。以下是小爱音箱智能家居控制的介绍： 支持的智能家居设备小爱音箱支持多种智能家居设备，包括但不限于： 灯光设备：如智能灯泡、智能灯带等； 空调设备：如智能空调、智能风扇等； 家电设备：如智能电视、智能音响等； 安防设备：如智能门锁、智能摄像头等； 其他设备：如智能窗帘、智能插座等。 控制方式小爱音箱可以通过语音控制智能家居设备，也可以通过小爱同学App进行控制。以下是具体的控制方式： 语音控制用户可以通过语音控制小爱音箱，例如： “小爱同学，打开卧室的灯。” “小爱同学，关闭客厅的电视。” “小爱同学，调高客厅的温度。” 小爱同学App控制用户可以通过小爱同学App进行智能家居设备的控制，例如： 在App中添加智能家居设备； 在App中设置智能家居设备的定时开关； 在App中查看智能家居设备的使用记录。 总结小爱音箱是一款智能音箱，可以通过语音控制智能家居设备。用户可以通过语音控制或者小爱同学App进行控制，支持多种智能家居设备。","categories":[{"name":"IT科技","slug":"IT科技","permalink":"https://skillixx.com/categories/IT%E7%A7%91%E6%8A%80/"}],"tags":[{"name":"小米","slug":"小米","permalink":"https://skillixx.com/tags/%E5%B0%8F%E7%B1%B3/"},{"name":"智能家居","slug":"智能家居","permalink":"https://skillixx.com/tags/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/"}],"keywords":[{"name":"IT科技","slug":"IT科技","permalink":"https://skillixx.com/categories/IT%E7%A7%91%E6%8A%80/"}]},{"title":"frp内容穿透后台启动","slug":"frp","date":"2023-05-10T02:25:40.000Z","updated":"2023-05-10T02:48:21.057Z","comments":false,"path":"fe1704c8.html","link":"","permalink":"https://skillixx.com/fe1704c8.html","excerpt":"","text":"Frp后台自动启动的几个方法本文介绍了在Linux和Windows系统中实现Frp后台自动启动的几种方法。 Linux系统方法一：使用nohup来启动使用nohup命令可以在后台启动Frp，具体步骤如下： 打开终端，输入以下命令启动frps： nohup /path/to/your/fprs -c-c /path/to/your/frps.ini &amp; 如果要查看日志，可以使用以下命令： cat nohup.out 同样的，使用以下命令启动frpc： nohup /path/to/your/fprc -c-c /path/to/your/frpc.ini &amp; 方法二：使用systemctl来控制启动使用systemctl命令可以方便地控制Frp的启动和停止，具体步骤如下： 在/lib/systemd/system/frps.service文件中写入以下内容： [Unit] Description=fraps service After=network.target syslog.target Wants=network.target [Service] Type=simple ExecStart=/your/path/frps -c /your/path/frps.ini [Install] WantedBy=multi-user.target 启动frps： sudo systemctl start frps 打开自启动： sudo systemctl enable frps 重启应用： sudo systemctl restart frps 停止应用： sudo systemctl stop frps 查看应用的日志： sudo systemctl status frps 方法三：使用supervisor来控制使用supervisor可以方便地控制Frp的启动和停止，具体步骤如下： 安装supervisor： sudo apt install supervisor 在/etc/supervisor/conf.d目录下创建frp.conf文件，写入以下内容： [program:frp] command = /your/path/frps -c /your/path/frps.ini autostart = true 重新加载supervisor： sudo systemctl restart supervisor 查看supervisor运行状态： sudo supervisorctl status Windows系统方法一：使用任务计划程序使用任务计划程序可以实现Frp开机自启，具体步骤如下： 打开任务计划程序，点击“创建任务”按钮。 输入任务名称，选择“使用最高权限运行”选项卡，然后选择“配置为Windows 7、Windows Server 2008 R2”。 在“触发器”选项卡中，选择“开机时”作为触发器。 在“操作”选项卡中，输入Frp的启动命令，比如： C:\\frp\\frpc.exe -c C:\\frp\\frpc.ini 点击“确定”按钮，保存任务。 方法二：使用注册表使用注册表可以实现Frp开机自启，具体步骤如下： 按下Win+R键，打开运行对话框，输入“regedit”打开注册表编辑器。 找到以下路径： HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run 在右侧窗口中，右键点击空白处，选择“新建”-&gt;“字符串值”。 输入一个名称，比如“Frp”，然后双击该项，输入Frp的启动命令，比如： C:\\frp\\frpc.exe -c C:\\frp\\frpc.ini 关闭注册表编辑器，重启电脑，Frp客户端就会自动启动了。 以上是在Linux和Windows系统中实现Frp后台自动启动的几种方法。","categories":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skillixx.com/tags/Linux/"},{"name":"frp","slug":"frp","permalink":"https://skillixx.com/tags/frp/"},{"name":"win","slug":"win","permalink":"https://skillixx.com/tags/win/"}],"keywords":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"入门Ansible","slug":"Ansible","date":"2023-05-08T11:01:18.000Z","updated":"2023-05-09T06:33:10.270Z","comments":false,"path":"4f3a6d14.html","link":"","permalink":"https://skillixx.com/4f3a6d14.html","excerpt":"","text":"本章内容 运维自动化发展历程及技术应用 Ansible命令使用 Ansible常用模块详解 YAML语法简介 Ansible playbook基础 Playbook变量、tags、handlers使用 Playbook模板templates Playbook条件判断 when Playbook字典 with_items Ansible Roles 运维自动化发展历程及技术应用 企业实际应用场景分析Dev开发环境 使用者：程序员 功能：程序员开发软件，测试BUG的环境 管理者：程序员 测试环境 使用者：QA测试工程师 功能：测试经过Dev环境测试通过的软件的功能 管理者：运维 说明：测试环境往往有多套,测试环境满足测试功能即可，不宜过多 1、测试人员希望测试环境有多套,公司的产品多产品线并发，即多个版本，意味着多个版本同步测试 2、通常测试环境有多少套和产品线数量保持一样 发布环境：代码发布机，有些公司为堡垒机（安全屏障） 使用者：运维 功能：发布代码至生产环境 管理者：运维（有经验） 发布机：往往需要有2台（主备） 生产环境 使用者：运维，少数情况开放权限给核心开发人员，极少数公司将权限完全 开放给开发人员并其维护 功能：对用户提供公司产品的服务 管理者：只能是运维 生产环境服务器数量：一般比较多，且应用非常重要。往往需要自动工具协助部署配置应用 灰度环境（生产环境的一部分） 使用者：运维 功能：在全量发布代码前将代码的功能面向少量精准用户发布的环境,可基 于主机或用户执行灰度发布 案例：共100台生产服务器，先发布其中的10台服务器，这10台服务器就是灰度服务器 管理者：运维 灰度环境：往往该版本功能变更较大，为保险起见特意先让一部分用户优化体验该功能， 待这部分用户使用没有重大问题的时候，再全量发布至所有服务器 程序发布程序发布要求： 不能导致系统故障或造成系统完全不可用 不能影响用户体验 预发布验证： 新版本的代码先发布到服务器（跟线上环境配置完全相同，只是未接入到调度器） 灰度发布： 基于主机，用户，业务 发布路径： /webapp/tuangou /webapp/tuangou-1.1 /webapp/tuangou-1.2 发布过程：在调度器上下线一批主机(标记为maintanance状态) --&gt; 关闭服务 --&gt; 部署新版本的应用程序 --&gt; 启动服务 --&gt; 在调度器上启用这一批服务器 自动化灰度发布：脚本、发布平台 运维自动化发展历程及技术应用 自动化运维应用场景文件传输 应用部署 配置管理 任务流编排 常用自动化运维工具Ansible：python，Agentless，中小型应用环境 Saltstack：python，一般需部署agent，执行效率更高 Puppet：ruby, 功能强大，配置复杂，重型,适合大型环境 Fabric：python，agentless Chef：ruby，国内应用少 Cfengine func 企业级自动化运维工具应用实战ansible公司计划在年底做一次大型市场促销活动，全面冲刺下交易额，为明年的上市做准备。 公司要求各业务组对年底大促做准备，运维部要求所有业务容量进行三倍的扩容， 并搭建出多套环境可以共开发和测试人员做测试，运维老大为了在年底有所表现， 要求运维部门同学尽快实现，当你接到这个任务时，有没有更快的解决方案？ Ansible发展史Ansible Michael DeHaan（ Cobbler 与 Func 作者） 名称来自《安德的游戏》中跨越时空的即时通信工具 2012-03-09，发布0.0.1版，2015-10-17，Red Hat宣布收购 官网：https://www.ansible.com/ 官方文档：https://docs.ansible.com/ 同类自动化工具GitHub关注程度（2016-07-10） 特性1&gt; 模块化：调用特定的模块，完成特定任务 2&gt; Paramiko（python对ssh的实现），PyYAML，Jinja2（模板语言）三个关键模块 3&gt; 支持自定义模块 4&gt; 基于Python语言实现 5&gt; 部署简单，基于python和SSH(默认已安装)，agentless 6&gt; 安全，基于OpenSSH 7&gt; 支持playbook编排任务 8&gt; 幂等性：一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况 9&gt; 无需代理不依赖PKI（无需ssl） 10&gt; 可使用任何编程语言写模块 11&gt; YAML格式，编排任务，支持丰富的数据结构 12&gt; 较强大的多层解决方案 Ansible架构 ansible的作用以及工作结构 1、ansible简介： ansible是新出现的自动化运维工具，基于Python开发， 集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点， 实现了批量系统配置、批量程序部署、批量运行命令等功能。 ansible是基于模块工作的，本身没有批量部署的能力。 真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。 主要包括： (1)、连接插件connection plugins：负责和被监控端实现通信； (2)、host inventory：指定操作的主机，是一个配置文件里面定义监控的主机； (3)、各种模块核心模块、command模块、自定义模块； (4)、借助于插件完成记录日志邮件等功能； (5)、playbook：剧本执行多个任务时，非必需可以让节点一次性运行多个任务。 2、ansible的架构：连接其他主机默认使用ssh协议 Ansible工作原理 Ansible主要组成部分ANSIBLE PLAYBOOKS：任务剧本（任务集），编排定义Ansible任务集的配置文件， 由Ansible顺序依次执行，通常是JSON格式的YML文件 INVENTORY：Ansible管理主机的清单 /etc/anaible/hosts MODULES： Ansible执行命令的功能模块，多数为内置核心模块，也可自定义 PLUGINS： 模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不常用 API： 供第三方程序调用的应用程序编程接口 ANSIBLE： 组合INVENTORY、API、MODULES、PLUGINS的绿框，可以理解为是ansible命令工具，其为核心执行工具 Ansible命令执行来源： 1&gt; USER，普通用户，即SYSTEM ADMINISTRATOR 2&gt; CMDB（配置管理数据库） API 调用 3&gt; PUBLIC/PRIVATE CLOUD API调用 (公有私有云的API接口调用) 4&gt; USER-&gt; Ansible Playbook -&gt; Ansibile 利用ansible实现管理的方式： 1&gt; Ad-Hoc 即ansible单条命令，主要用于临时命令使用场景 2&gt; Ansible-playbook 主要用于长期规划好的，大型项目的场景，需要有前期的规划过程 Ansible-playbook（剧本）执行过程 将已有编排好的任务集写入Ansible-Playbook 通过ansible-playbook命令分拆任务集至逐条ansible命令，按预定规则逐条执行 Ansible主要操作对象 HOSTS主机 NETWORKING网络设备 注意事项: 执行ansible的主机一般称为主控端，中控，master或堡垒机 主控端Python版本需要2.6或以上 被控端Python版本小于2.4需要安装python-simplejson 被控端如开启SELinux需要安装libselinux-python windows不能做为主控端 ansible不是服务,不会一直启动,只是需要的时候启动 安装rpm包安装: EPEL源 yum install ansible 编译安装: yum -y install python-jinja2 PyYAML python-paramiko python-babel python-crypto tar xf ansible-1.5.4.tar.gz cd ansible-1.5.4 python setup.py build python setup.py install mkdir /etc/ansible cp -r examples/* /etc/ansible Git方式: git clone git://github.com/ansible/ansible.git --recursive cd ./ansible source ./hacking/env-setup pip安装： pip是安装Python包的管理器，类似yum yum install python-pip python-devel yum install gcc glibc-devel zibl-devel rpm-bulid openssl-devel pip install --upgrade pip pip install ansible --upgrade 确认安装： ansible --version 相关文件配置文件 /etc/ansible/ansible.cfg 主配置文件,配置ansible工作特性(一般无需修改) /etc/ansible/hosts 主机清单(将被管理的主机放到此文件) /etc/ansible/roles/ 存放角色的目录 程序 /usr/bin/ansible 主程序，临时命令执行工具 /usr/bin/ansible-doc 查看配置文档，模块功能查看工具 /usr/bin/ansible-galaxy 下载/上传优秀代码或Roles模块的官网平台 /usr/bin/ansible-playbook 定制自动化任务，编排剧本工具 /usr/bin/ansible-pull 远程执行命令的工具 /usr/bin/ansible-vault 文件加密工具 /usr/bin/ansible-console 基于Console界面与用户交互的执行工具 主机清单inventoryInventory 主机清单 1&gt; ansible的主要功用在于批量主机操作，为了便捷地使用其中的部分主机，可以在inventory file中将其分组命名 2&gt; 默认的inventory file为/etc/ansible/hosts 3&gt; inventory file可以有多个，且也可以通过Dynamic Inventory来动态生成 /etc/ansible/hosts文件格式 inventory文件遵循INI文件风格，中括号中的字符为组名。 可以将同一个主机同时归并到多个不同的组中； 此外，当如若目标主机使用了非默认的SSH端口，还可以在主机名称之后使用冒号加端口号来标明 ntp.magedu.com 不分组,直接加 [webservers] webservers组 www1.magedu.com:2222 可以指定端口 www2.magedu.com [dbservers] db1.magedu.com db2.magedu.com db3.magedu.com 如果主机名称遵循相似的命名模式，还可以使用列表的方式标识各主机 示例： [websrvs] www[1:100].example.com ip: 1-100 [dbsrvs] db-[a:f].example.com dba-dbff ansible 配置文件Ansible 配置文件/etc/ansible/ansible.cfg （一般保持默认） vim /etc/ansible/ansible.cfg [defaults] #inventory = /etc/ansible/hosts # 主机列表配置文件 #library = /usr/share/my_modules/ # 库文件存放目录 #remote_tmp = $HOME/.ansible/tmp # 临时py命令文件存放在远程主机目录 #local_tmp = $HOME/.ansible/tmp # 本机的临时命令执行目录 #forks = 5 # 默认并发数,同时可以执行5次 #sudo_user = root # 默认sudo 用户 #ask_sudo_pass = True # 每次执行ansible命令是否询问ssh密码 #ask_pass = True # 每次执行ansible命令是否询问ssh口令 #remote_port = 22 # 远程主机的端口号(默认22) 建议优化项： host_key_checking = False # 检查对应服务器的host_key，建议取消注释 log_path=/var/log/ansible.log # 日志文件,建议取消注释 module_name = command # 默认模块 ansible系列命令Ansible系列命令 ansible ansible-doc ansible-playbook ansible-vault ansible-console ansible-galaxy ansible-pull ansible-doc: 显示模块帮助 ansible-doc [options] [module...] -a 显示所有模块的文档 -l, --list 列出可用模块 -s, --snippet 显示指定模块的playbook片段(简化版,便于查找语法) 示例： ansible-doc -l 列出所有模块 ansible-doc ping 查看指定模块帮助用法 ansible-doc -s ping 查看指定模块帮助用法 ansibleansible通过ssh实现配置管理、应用部署、任务执行等功能， 建议配置ansible端能基于密钥认证的方式联系各被管理节点 ansible &lt;host-pattern&gt; [-m module_name] [-a args] ansible +被管理的主机(ALL) +模块 +参数 --version 显示版本 -m module 指定模块，默认为command -v 详细过程 –vv -vvv更详细 --list-hosts 显示主机列表，可简写 --list -k, --ask-pass 提示输入ssh连接密码,默认Key验证 -C, --check 检查，并不执行 -T, --timeout=TIMEOUT 执行命令的超时时间,默认10s -u, --user=REMOTE_USER 执行远程执行的用户 -b, --become 代替旧版的sudo切换 --become-user=USERNAME 指定sudo的runas用户,默认为root -K, --ask-become-pass 提示输入sudo时的口令 ansible all --list 列出所有主机 ping模块: 探测网络中被管理主机是否能够正常使用 走ssh协议 如果对方主机网络正常,返回pong ansible-doc -s ping 查看ping模块的语法 检测所有主机的网络状态 1&gt; 默认情况下连接被管理的主机是ssh基于key验证,如果没有配置key,权限将会被拒绝 因此需要指定以谁的身份连接,输入用户密码,必须保证被管理主机用户密码一致 ansible all -m ping -k 2&gt; 或者实现基于key验证 将公钥ssh-copy-id到被管理的主机上 , 实现免密登录 ansible all -m ping ansible的Host-patternansible的Host-pattern 匹配主机的列表 All ：表示所有Inventory中的所有主机 ansible all –m ping * :通配符 ansible &quot;*&quot; -m ping (*表示所有主机) ansible 192.168.1.* -m ping ansible &quot;*srvs&quot; -m ping 或关系 &quot;:&quot; ansible &quot;websrvs:appsrvs&quot; -m ping ansible “192.168.1.10:192.168.1.20” -m ping 逻辑与 &quot;:&amp;&quot; ansible &quot;websrvs:&amp;dbsrvs&quot; –m ping 在websrvs组并且在dbsrvs组中的主机 逻辑非 &quot;:!&quot; ansible &#39;websrvs:!dbsrvs&#39; –m ping 在websrvs组，但不在dbsrvs组中的主机 注意：此处为单引号 综合逻辑 ansible &#39;websrvs:dbsrvs:&amp;appsrvs:!ftpsrvs&#39; –m ping 正则表达式 ansible &quot;websrvs:&amp;dbsrvs&quot; –m ping ansible &quot;~(web|db).*\\.magedu\\.com&quot; –m ping ansible命令执行过程ansible命令执行过程 1. 加载自己的配置文件 默认/etc/ansible/ansible.cfg 2. 加载自己对应的模块文件，如command 3. 通过ansible将模块或命令生成对应的临时py文件， 并将该文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/XXX.PY文件 4. 给文件+x执行 5. 执行并返回结果 6. 删除临时py文件，sleep 0退出 执行状态： 绿色：执行成功并且不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 ansible使用示例示例 以wang用户执行ping存活检测 ansible all -m ping -u wang -k 以wang sudo至root执行ping存活检测 ansible all -m ping -u wang -k -b 以wang sudo至mage用户执行ping存活检测 ansible all -m ping -u wang -k -b --become-user=mage 以wang sudo至root用户执行ls ansible all -m command -u wang -a &#39;ls /root&#39; -b --become-user=root -k -K ansible ping模块测试连接 ansible 192.168.38.126,192.168.38.127 -m ping -k ansible常用模块模块文档：https://docs.ansible.com/ansible/latest/modules/modules_by_category.html Command：在远程主机执行命令，默认模块，可忽略-m选项 &gt; ansible srvs -m command -a &#39;service vsftpd start&#39; &gt; ansible srvs -m command -a &#39;echo adong |passwd --stdin 123456&#39; 此命令不支持 $VARNAME &lt; &gt; | ; &amp; 等,用shell模块实现 chdir: 进入到被管理主机目录 creates: 如果有一个目录是存在的,步骤将不会运行Command命令 ansible websrvs -a &#39;chdir=/data/ ls&#39; Shell：和command相似，用shell执行命令 &gt; ansible all -m shell -a &#39;getenforce&#39; 查看SELINUX状态 &gt; ansible all -m shell -a &quot;sed -i &#39;s/SELINUX=.*/SELINUX=disabled&#39; /etc/selinux/config&quot; &gt; ansible srv -m shell -a &#39;echo magedu |passwd –stdin wang&#39; 调用bash执行命令 类似 cat /tmp/stanley.md | awk -F&#39;|&#39; &#39;&#123;print $1,$2&#125;&#39; &amp;&gt; /tmp/example.txt 这些复杂命令，即使使用shell也可能会失败， 解决办法：写到脚本时，copy到远程执行，再把需要的结果拉回执行命令的机器 修改配置文件,使shell作为默认模块 vim /etc/ansible/ansible.cfg module_name = shell Script：在远程主机上运行ansible服务器上的脚本 &gt; -a &quot;/PATH/TO/SCRIPT_FILE&quot; &gt; ansible websrvs -m script -a /data/test.sh Copy：从主控端复制文件到远程主机 src : 源文件 指定拷贝文件的本地路径 (如果有/ 则拷贝目录内容,比拷贝目录本身) dest: 指定目标路径 mode: 设置权限 backup: 备份源文件 content: 代替src 指定本机文件内容,生成目标主机文件 &gt; ansible websrvs -m copy -a &quot;src=/root/test1.sh dest=/tmp/test2.showner=wang mode=600 backup=yes&quot; 如果目标存在，默认覆盖，此处指定先备份 &gt; ansible websrvs -m copy -a &quot;content=&#39;test content\\nxxx&#39; dest=/tmp/test.txt&quot; 指定内容，直接生成目标文件 Fetch：从远程主机提取文件至主控端，copy相反，目前不支持目录,可以先打包,再提取文件 &gt; ansible websrvs -m fetch -a &#39;src=/root/test.sh dest=/data/scripts&#39; 会生成每个被管理主机不同编号的目录,不会发生文件名冲突 &gt; ansible all -m shell -a &#39;tar jxvf test.tar.gz /root/test.sh&#39; &gt; ansible all -m fetch -a &#39;src=/root/test.tar.gz dest=/data/&#39; File：设置文件属性 path: 要管理的文件路径 (强制添加) recurse: 递归,文件夹要用递归 src: 创建硬链接,软链接时,指定源目标,配合&#39;state=link&#39; &#39;state=hard&#39; 设置软链接,硬链接 state: 状态 absent 缺席,删除 &gt; ansible websrvs -m file -a &#39;path=/app/test.txt state=touch&#39; 创建文件 &gt; ansible websrvs -m file -a &quot;path=/data/testdir state=directory&quot; 创建目录 &gt; ansible websrvs -m file -a &quot;path=/root/test.sh owner=wang mode=755&quot; 设置权限755 &gt; ansible websrvs -m file -a &#39;src=/data/testfile dest=/data/testfile-link state=link&#39; 创建软链接 unarchive：解包解压缩，有两种用法： 1、将ansible主机上的压缩包传到远程主机后解压缩至特定目录，设置copy=yes. 2、将远程主机上的某个压缩包解压缩到指定路径下，设置copy=no 常见参数： copy：默认为yes，当copy=yes，拷贝的文件是从ansible主机复制到远程主机上， 如果设置为copy=no，会在远程主机上寻找src源文件 src： 源路径，可以是ansible主机上的路径，也可以是远程主机上的路径， 如果是远程主机上的路径，则需要设置copy=no dest：远程主机上的目标路径 mode：设置解压缩后的文件权限 示例： ansible websrvs -m unarchive -a &#39;src=foo.tgz dest=/var/lib/foo&#39; #默认copy为yes ,将本机目录文件解压到目标主机对应目录下 ansible websrvs -m unarchive -a &#39;src=/tmp/foo.zip dest=/data copy=no mode=0777&#39; # 解压被管理主机的foo.zip到data目录下, 并设置权限777 ansible websrvs -m unarchive -a &#39;src=https://example.com/example.zip dest=/data copy=no&#39; Archive：打包压缩 &gt; ansible all -m archive -a &#39;path=/etc/sysconfig dest=/data/sysconfig.tar.bz2 format=bz2 owner=wang mode=0777&#39; 将远程主机目录打包 path: 指定路径 dest: 指定目标文件 format: 指定打包格式 owner: 指定所属者 mode: 设置权限 Hostname：管理主机名 ansible appsrvs -m hostname -a &quot;name=app.adong.com&quot; 更改一组的主机名 ansible 192.168.38.103 -m hostname -a &quot;name=app2.adong.com&quot; 更改单个主机名 Cron：计划任务 支持时间：minute,hour,day,month,weekday &gt; ansible websrvs -m cron -a &quot;minute=*/5 job=&#39;/usr/sbin/ntpdate 172.16.0.1 &amp;&gt;/dev/null&#39; name=Synctime&quot; 创建任务 &gt; ansible websrvs -m cron -a &#39;state=absent name=Synctime&#39; 删除任务 &gt; ansible websrvs -m cron -a &#39;minute=*/10 job=&#39;/usr/sbin/ntpdate 172.30.0.100&quot; name=synctime disabled=yes&#39; 注释任务,不在生效 Yum：管理包 ansible websrvs -m yum -a &#39;list=httpd&#39; 查看程序列表 ansible websrvs -m yum -a &#39;name=httpd state=present&#39; 安装 ansible websrvs -m yum -a &#39;name=httpd state=absent&#39; 删除 可以同时安装多个程序包 Service：管理服务 ansible srv -m service -a &#39;name=httpd state=stopped&#39; 停止服务 ansible srv -m service -a &#39;name=httpd state=started enabled=yes&#39; 启动服务,并设为开机自启 ansible srv -m service -a &#39;name=httpd state=reloaded&#39; 重新加载 ansible srv -m service -a &#39;name=httpd state=restarted&#39; 重启服务 User：管理用户 home 指定家目录路径 system 指定系统账号 group 指定组 remove 清除账户 shell 指定shell类型 ansible websrvs -m user -a &#39;name=user1 comment=&quot;test user&quot; uid=2048 home=/app/user1 group=root&#39; ansible websrvs -m user -a &#39;name=sysuser1 system=yes home=/app/sysuser1&#39; ansible websrvs -m user -a &#39;name=user1 state=absent remove=yes&#39; 清空用户所有数据 ansible websrvs -m user -a &#39;name=app uid=88 system=yes home=/app groups=root shell=/sbin/nologin password=&quot;$1$zfVojmPy$ZILcvxnXljvTI2PhP2Iqv1&quot;&#39; 创建用户 ansible websrvs -m user -a &#39;name=app state=absent&#39; 不会删除家目录 安装mkpasswd yum insatll expect mkpasswd 生成口令 openssl passwd -1 生成加密口令 删除用户及家目录等数据 Group：管理组 ansible srv -m group -a &quot;name=testgroup system=yes&quot; 创建组 ansible srv -m group -a &quot;name=testgroup state=absent&quot; 删除组 ansible系列命令可以通过网上写好的 ansible-galaxy &gt; 连接 https://galaxy.ansible.com 下载相应的roles(角色) &gt; 列出所有已安装的galaxy ansible-galaxy list &gt; 安装galaxy ansible-galaxy install geerlingguy.redis &gt; 删除galaxy ansible-galaxy remove geerlingguy.redis ansible-pull 推送命令至远程，效率无限提升，对运维要求较高 ansible-playbook 可以引用按照标准的yml语言写的脚本 执行playbook 示例：ansible-playbook hello.yml cat hello.yml #hello world yml file - hosts: websrvs remote_user: root tasks: - name: hello world command: /usr/bin/wall hello world ansible-vault (了解) 功能：管理加密解密yml文件 ansible-vault [create|decrypt|edit|encrypt|rekey|view] ansible-vault encrypt hello.yml 加密 ansible-vault decrypt hello.yml 解密 ansible-vault view hello.yml 查看 ansible-vault edit hello.yml 编辑加密文件 ansible-vault rekey hello.yml 修改口令 ansible-vault create new.yml 创建新文件 Ansible-console：2.0+新增，可交互执行命令，支持tab (了解) root@test (2)[f:10] $ 执行用户@当前操作的主机组 (当前组的主机数量)[f:并发数]$ 设置并发数： forks n 例如： forks 10 切换组： cd 主机组 例如： cd web 列出当前组主机列表： list 列出所有的内置命令： ?或help 示例： root@all (2)[f:5]$ list root@all (2)[f:5]$ cd appsrvs root@appsrvs (2)[f:5]$ list root@appsrvs (2)[f:5]$ yum name=httpd state=present root@appsrvs (2)[f:5]$ service name=httpd state=started playbook&gt; playbook是由一个或多个&quot;play&quot;组成的列表 &gt; play的主要功能在于将预定义的一组主机，装扮成事先通过ansible中的task定义好的角色。 Task实际是调用ansible的一个module，将多个play组织在一个playbook中， 即可以让它们联合起来，按事先编排的机制执行预定义的动作 &gt; Playbook采用YAML语言编写 playbook图解 用户通过ansible命令直接调用yml语言写好的playbook,playbook由多条play组成 每条play都有一个任务(task)相对应的操作,然后调用模块modules，应用在主机清单上,通过ssh远程连接 从而控制远程主机或者网络设备 YAML介绍YAML是一个可读性高的用来表达资料序列的格式。 YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。 Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者 YAML Ain&#39;t Markup Language，即YAML不是XML。 不过，在开发的这种语言时，YAML的意思其实是：&quot;Yet Another Markup Language&quot;（仍是一种标记语言） 特性 YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强，扩展性好 更多的内容及规范参见：http://www.yaml.org YAML语法简介&gt; 在单一档案中，可用连续三个连字号(——)区分多个档案。 另外，还有选择性的连续三个点号( ... )用来表示档案结尾 &gt; 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 &gt; 使用#号注释代码 &gt; 缩进必须是统一的，不能空格和tab混用 &gt; 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过缩进结合换行来实现的 &gt; YAML文件内容是区别大小写的，k/v的值均需大小写敏感 &gt; 多个k/v可同行写也可换行写，同行使用:分隔 &gt; v可是个字符串，也可是另一个列表[] &gt; 一个完整的代码块功能需最少元素需包括 name 和 task &gt; 一个name只能包括一个task &gt; YAML文件扩展名通常为yml或yaml YAML语法简介List：列表，其所有元素均使用“-”打头 列表代表同一类型的元素 示例： # A list of tasty fruits - Apple - Orange - Strawberry - Mango Dictionary：字典，通常由多个key与value构成 键值对 示例： --- # An employee record name: Example Developer job: Developer skill: Elite 也可以将key:value放置于&#123;&#125;中进行表示，用,分隔多个key:value 示例： --- # An employee record &#123;name: Example Developer, job: Developer, skill: Elite&#125; 有空格 YAML语法YAML的语法和其他高阶语言类似，并且可以简单表达清单、散列表、标量等数据结构。 其结构（Structure）通过空格来展示，序列（Sequence）里的项用&quot;-&quot;来代表，Map里的键值对用&quot;:&quot;分隔 示例 name: John Smith age: 41 gender: Male spouse: name: Jane Smith age: 37 gender: Female children: - name: Jimmy Smith age: 17 gender: Male - name: Jenny Smith age 13 gender: Female 三种常见的数据交换格式 Playbook核心元素Hosts 执行的远程主机列表(应用在哪些主机上) Tasks 任务集 Variables 内置变量或自定义变量在playbook中调用 Templates模板 可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers和notify结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行 tags标签 指定某条任务执行，用于选择运行playbook中的部分代码。 ansible具有幂等性，因此会自动跳过没有变化的部分， 即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。 此时，如果确信其没有变化，就可以通过tags跳过此些代码片断 ansible-playbook -t tagsname useradd.yml playbook基础组件Hosts： &gt; playbook中的每一个play的目的都是为了让特定主机以某个指定的用户身份执行任务。 hosts用于指定要执行指定任务的主机，须事先定义在主机清单中 &gt; 可以是如下形式： one.example.com one.example.com:two.example.com 192.168.1.50 192.168.1.* &gt; Websrvs:dbsrvs 或者，两个组的并集 &gt; Websrvs:&amp;dbsrvs 与，两个组的交集 &gt; webservers:!phoenix 在websrvs组，但不在dbsrvs组 示例: - hosts: websrvs：dbsrvs remote_user: 可用于Host和task中。 也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务； 此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户 - hosts: websrvs remote_user: root (可省略,默认为root) 以root身份连接 tasks: 指定任务 - name: test connection ping: remote_user: magedu sudo: yes 默认sudo为root sudo_user:wang sudo为wang task列表和action 任务列表task:由多个动作,多个任务组合起来的,每个任务都调用的模块,一个模块一个模块执行 1&gt; play的主体部分是task list，task list中的各任务按次序逐个在hosts中指定的所有主机上执行， 即在所有主机上完成第一个任务后，再开始第二个任务 2&gt; task的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。 模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致 3&gt; 每个task都应该有其name，用于playbook的执行结果输出，建议其内容能清晰地描述任务执行步骤。 如果未提供name，则action的结果将用于输出 tasks：任务列表 两种格式： (1) action: module arguments (2) module: arguments 建议使用 模块: 参数 注意：shell和command模块后面跟命令，而非key=value 某任务的状态在运行后为changed时，可通过&quot;notify&quot;通知给相应的handlers 任务可以通过&quot;tags&quot;打标签，可在ansible-playbook命令上使用-t指定进行调用 示例： tasks: - name: disable selinux 描述 command: /sbin/setenforce 0 模块名: 模块对应的参数 如果命令或脚本的退出码不为零，可以使用如下方式替代 tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true 转错为正 如果命令失败则执行 true 或者使用ignore_errors来忽略错误信息 tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True 忽略错误 运行playbook运行playbook的方式 ansible-playbook &lt;filename.yml&gt; ... [options] 常见选项 --check -C 只检测可能会发生的改变，但不真正执行操作 (只检查语法,如果执行过程中出现问题,-C无法检测出来) (执行playbook生成的文件不存在,后面的程序如果依赖这些文件,也会导致检测失败) --list-hosts 列出运行任务的主机 --list-tags 列出tag (列出标签) --list-tasks 列出task (列出任务) --limit 主机列表 只针对主机列表中的主机执行 -v -vv -vvv 显示过程 示例 ansible-playbook hello.yml --check 只检测 ansible-playbook hello.yml --list-hosts 显示运行任务的主机 ansible-playbook hello.yml --limit websrvs 限制主机 Playbook VS ShellScripts安装httpd SHELL脚本 #!/bin/bash # 安装Apache yum install --quiet -y httpd # 复制配置文件 cp /tmp/httpd.conf /etc/httpd/conf/httpd.conf cp/tmp/vhosts.conf /etc/httpd/conf.d/ # 启动Apache，并设置开机启动 service httpd start chkconfig httpd on Playbook定义 --- - hosts: all remote_user: root tasks: - name: &quot;安装Apache&quot; yum: name=httpd yum模块:安装httpd - name: &quot;复制配置文件&quot; copy: src=/tmp/httpd.conf dest=/etc/httpd/conf/ copy模块: 拷贝文件 - name: &quot;复制配置文件&quot; copy: src=/tmp/vhosts.conf dest=/etc/httpd/conf.d/ - name: &quot;启动Apache，并设置开机启动&quot; service: name=httpd state=started enabled=yes service模块: 启动服务 示例:Playbook 创建用户示例：sysuser.yml --- - hosts: all remote_user: root tasks: - name: create mysql user user: name=mysql system=yes uid=36 - name: create a group group: name=httpd system=yes Playbook示例 安装httpd服务示例：httpd.yml - hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ - name: start service service: name=httpd state=started enabled=yes Playbook示例 安装nginx服务示例 nginx.yml - hosts: all remote_user: root tasks: - name: add group nginx user: name=nginx state=present - name: add user nginx user: name=nginx state=present group=nginx - name: Install Nginx yum: name=nginx state=present - name: Start Nginx service: name=nginx state=started enabled=yes handlers和notify结合使用触发条件Handlers 实际上就是一个触发器 是task列表，这些task与前述的task并没有本质上的不同,用于当关注的资源发生变化时，才会采取一定的操作 Notify此action可用于在每个play的最后被触发， 这样可避免多次有改变发生时每次都执行指定的操作，仅在所有的变化发生完成后一次性地执行指定操作。 在notify中列出的操作称为handler，也即notify中调用handler中定义的操作 Playbook中handlers使用- hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ notify: restart httpd - name: ensure apache is running service: name=httpd state=started enabled=yes handlers: - name: restart httpd service: name=httpd state=restarted 示例- hosts: webnodes vars: http_port: 80 max_clients: 256 remote_user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: ensure apache is running service: name=httpd state=started - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ notify: restart httpd handlers: - name: restart httpd service: name=httpd state=restarted 示例- hosts: websrvs remote_user: root tasks: - name: add group nginx tags: user user: name=nginx state=present - name: add user nginx user: name=nginx state=present group=nginx - name: Install Nginx yum: name=nginx state=present - name: config copy: src=/root/config.txt dest=/etc/nginx/nginx.conf notify: - Restart Nginx - Check Nginx Process handlers: - name: Restart Nginx service: name=nginx state=restarted enabled=yes - name: Check Nginx process shell: killall -0 nginx &gt; /tmp/nginx.log Playbook中tags使用tage: 添加标签 可以指定某一个任务添加一个标签,添加标签以后,想执行某个动作可以做出挑选来执行 多个动作可以使用同一个标签 示例：httpd.yml - hosts: websrvs remote_user: root tasks: - name: Install httpd yum: name=httpd state=present tage: install - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ tags: conf - name: start httpd service tags: service service: name=httpd state=started enabled=yes ansible-playbook –t install,conf httpd.yml 指定执行install,conf 两个标签 示例//heartbeat.yaml - hosts: hbhosts remote_user: root tasks: - name: ensure heartbeat latest version yum: name=heartbeat state=present - name: authkeys configure file copy: src=/root/hb_conf/authkeys dest=/etc/ha.d/authkeys - name: authkeys mode 600 file: path=/etc/ha.d/authkeys mode=600 notify: - restart heartbeat - name: ha.cf configure file copy: src=/root/hb_conf/ha.cf dest=/etc/ha.d/ha.cf notify: - restart heartbeat handlers: - name: restart heartbeat service: name=heartbeat state=restarted Playbook中tags使用- hosts: testsrv remote_user: root tags: inshttpd 针对整个playbook添加tage tasks: - name: Install httpd yum: name=httpd state=present - name: Install configure file copy: src=files/httpd.conf dest=/etc/httpd/conf/ tags: rshttpd notify: restart httpd handlers: - name: restart httpd service: name=httpd status=restarted ansible-playbook –t rshttpd httpd2.yml Playbook中变量的使用变量名：仅能由字母、数字和下划线组成，且只能以字母开头 变量来源： 1&gt; ansible setup facts 远程主机的所有变量都可直接调用 (系统自带变量) setup模块可以实现系统中很多系统信息的显示 可以返回每个主机的系统信息包括:版本、主机名、cpu、内存 ansible all -m setup -a &#39;filter=&quot;ansible_nodename&quot;&#39; 查询主机名 ansible all -m setup -a &#39;filter=&quot;ansible_memtotal_mb&quot;&#39; 查询主机内存大小 ansible all -m setup -a &#39;filter=&quot;ansible_distribution_major_version&quot;&#39; 查询系统版本 ansible all -m setup -a &#39;filter=&quot;ansible_processor_vcpus&quot;&#39; 查询主机cpu个数 2&gt; 在/etc/ansible/hosts(主机清单)中定义变量 普通变量：主机组中主机单独定义，优先级高于公共变量(单个主机 ) 公共(组)变量：针对主机组中所有主机定义统一变量(一组主机的同一类别) 3&gt; 通过命令行指定变量，优先级最高 ansible-playbook –e varname=value 4&gt; 在playbook中定义 vars: - var1: value1 - var2: value2 5&gt; 在独立的变量YAML文件中定义 6&gt; 在role中定义 变量命名: 变量名仅能由字母、数字和下划线组成，且只能以字母开头 变量定义：key=value 示例：http_port=80 变量调用方式： 1&gt; 通过&#123;&#123; variable_name &#125;&#125; 调用变量，且变量名前后必须有空格，有时用“&#123;&#123; variable_name &#125;&#125;”才生效 2&gt; ansible-playbook –e 选项指定 ansible-playbook test.yml -e &quot;hosts=www user=magedu&quot; 在主机清单中定义变量,在ansible中使用变量 vim /etc/ansible/hosts [appsrvs] 192.168.38.17 http_port=817 name=www 192.168.38.27 http_port=827 name=web 调用变量 ansible appsrvs -m hostname -a&#39;name=&#123;&#123;name&#125;&#125;&#39; 更改主机名为各自被定义的变量 针对一组设置变量 [appsrvs:vars] make=&quot;-&quot; ansible appsrvs -m hostname -a &#39;name=&#123;&#123;name&#125;&#125;&#123;&#123;mark&#125;&#125;&#123;&#123;http_port&#125;&#125;&#39; ansible调用变量 将变量写进单独的配置文件中引用 vim vars.yml pack: vsftpd service: vsftpd 引用变量文件 vars_files: - vars.yml Ansible基础元素Facts：是由正在通信的远程目标主机发回的信息，这些信息被保存在ansible变量中。 要获取指定的远程主机所支持的所有facts，可使用如下命令进行 ansible websrvs -m setup 通过命令行传递变量 在运行playbook的时候也可以传递一些变量供playbook使用 示例： ansible-playbook test.yml -e &quot;hosts=www user=magedu&quot; register 把任务的输出定义为变量，然后用于其他任务 示例: tasks: - shell: /usr/bin/foo register: foo_result ignore_errors: True 示例：使用setup变量示例：var.yml - hosts: websrvs remote_user: root tasks: - name: create log file file: name=/var/log/ &#123;&#123; ansible_fqdn &#125;&#125; state=touch ansible-playbook var.yml 示例：变量示例：var.yml - hosts: websrvs remote_user: root tasks: - name: install package yum: name=&#123;&#123; pkname &#125;&#125; state=present ansible-playbook –e pkname=httpd var.yml 示例：变量示例：var.yml - hosts: websrvs remote_user: root vars: - username: user1 - groupname: group1 tasks: - name: create group group: name=&#123;&#123; groupname &#125;&#125; state=present - name: create user user: name=&#123;&#123; username &#125;&#125; state=present ansible-playbook var.yml ansible-playbook -e &quot;username=user2 groupname=group2” var2.yml 变量主机变量 可以在inventory中定义主机时为其添加主机变量以便于在playbook中使用 示例： [websrvs] www1.magedu.com http_port=80 maxRequestsPerChild=808 www2.magedu.com http_port=8080 maxRequestsPerChild=909 组变量 组变量是指赋予给指定组内所有主机上的在playbook中可用的变量 示例： [websrvs] www1.magedu.com www2.magedu.com [websrvs:vars] ntp_server=ntp.magedu.com nfs_server=nfs.magedu.com 示例：变量普通变量 [websrvs] 192.168.99.101 http_port=8080 hname=www1 192.168.99.102 http_port=80 hname=www2 公共（组）变量 [websvrs:vars] http_port=808 mark=&quot;_&quot; [websrvs] 192.168.99.101 http_port=8080 hname=www1 192.168.99.102 http_port=80 hname=www2 ansible websvrs –m hostname –a ‘name=&#123;&#123; hname &#125;&#125;&#123;&#123; mark &#125;&#125;&#123;&#123; http_port &#125;&#125;’ 命令行指定变量： ansible websvrs –e http_port=8000 –m hostname –a&#39;name=&#123;&#123; hname &#125;&#125;&#123;&#123; mark &#125;&#125;&#123;&#123; http_port &#125;&#125;&#39; 使用变量文件cat vars.yml var1: httpd var2: nginx cat var.yml - hosts: web remote_user: root vars_files: - vars.yml tasks: - name: create httpd log file: name=/app/&#123;&#123; var1 &#125;&#125;.log state=touch - name: create nginx log file: name=/app/&#123;&#123; var2 &#125;&#125;.log state=touch hostname app_81.magedu.com hostname 不支持&quot;_&quot;,认为&quot;_&quot;是非法字符 hostnamectl set-hostname app_80.magedu.com 可以更改主机名 变量组嵌套 inventory中，组还可以包含其它的组，并且也可以向组中的主机指定变量。 这些变量只能在ansible-playbook中使用，而ansible命令不支持 示例： [apache] httpd1.magedu.com httpd2.magedu.com [nginx] ngx1.magedu.com ngx2.magedu.com [websrvs:children] apache nginx [webservers:vars] ntp_server=ntp.magedu.com invertory参数invertory参数：用于定义ansible远程连接目标主机时使用的参数，而非传递给playbook的变量 ansible_ssh_host ansible_ssh_port ansible_ssh_user ansible_ssh_pass ansbile_sudo_pass 示例： cat /etc/ansible/hosts [websrvs] 192.168.0.1 ansible_ssh_user=root ansible_ssh_pass=magedu 192.168.0.2 ansible_ssh_user=root ansible_ssh_pass=magedu invertory参数inventory参数 ansible基于ssh连接inventory中指定的远程主机时，还可以通过参数指定其交互方式； 这些参数如下所示： ansible_ssh_host The name of the host to connect to, if different from the alias you wishto give to it. ansible_ssh_port The ssh port number, if not 22 ansible_ssh_user The default ssh user name to use. ansible_ssh_pass The ssh password to use (this is insecure, we strongly recommendusing --ask-pass or SSH keys) ansible_sudo_pass The sudo password to use (this is insecure, we strongly recommendusing --ask-sudo-pass) ansible_connection Connection type of the host. Candidates are local, ssh or paramiko. The default is paramiko before Ansible 1.2, and &#39;smart&#39; afterwards which detects whether usage of &#39;ssh&#39; would be feasible based on whether ControlPersist is supported. ansible_ssh_private_key_file Private key file used by ssh. Useful if using multiple keys and you don&#39;t want to use SSH agent. ansible_shell_type The shell type of the target system. By default commands are formatted using &#39;sh&#39;-style syntax by default. Setting this to &#39;csh&#39; or &#39;fish&#39; will cause commands executed on target systems to follow those shell&#39;s syntax instead. ansible_python_interpreter The target host python path. This is useful for systems with more than one Python or not located at &quot;/usr/bin/python&quot; such as \\*BSD, or where /usr/bin/python is not a 2.X series Python. We do not use the &quot;/usr/bin/env&quot; mechanism as that requires the remote user&#39;s path to be set right and also assumes the &quot;python&quot; executable is named python,where the executable might be named something like &quot;python26&quot;. ansible\\_\\*\\_interpreter Works for anything such as ruby or perl and works just like ansible_python_interpreter. This replaces shebang of modules which will run on that host. 模板templates文本文件，嵌套有脚本（使用模板编程语言编写） 借助模板生成真正的文件 Jinja2语言，使用字面量，有下面形式 字符串：使用单引号或双引号 数字：整数，浮点数 列表：[item1, item2, ...] 元组：(item1, item2, ...) 字典：&#123;key1:value1, key2:value2, ...&#125; 布尔型：true/false 算术运算：+, -, *, /, //, %, ** 比较操作：==, !=, &gt;, &gt;=, &lt;, &lt;= 逻辑运算：and，or，not 流表达式：For，If，When Jinja2相关字面量 1&gt; 表达式最简单的形式就是字面量。字面量表示诸如字符串和数值的 Python对象。如“Hello World” 双引号或单引号中间的一切都是字符串。 2&gt; 无论何时你需要在模板中使用一个字符串（比如函数调用、过滤器或只是包含或继承一个模板的参数），如4242.23 3&gt; 数值可以为整数和浮点数。如果有小数点，则为浮点数，否则为整数。在Python 里， 42 和 42.0 是不一样的 Jinja2:算术运算算术运算 Jinja 允许你用计算值。这在模板中很少用到，但为了完整性允许其存在 支持下面的运算符 +：把两个对象加到一起。 通常对象是素质，但是如果两者是字符串或列表，你可以用这 种方式来衔接它们。 无论如何这不是首选的连接字符串的方式！连接字符串见 ~ 运算符。 &#123;&#123; 1 + 1 &#125;&#125; 等于 2 -：用第一个数减去第二个数。 &#123;&#123; 3 - 2 &#125;&#125; 等于 1 /：对两个数做除法。返回值会是一个浮点数。 &#123;&#123; 1 / 2 &#125;&#125; 等于 &#123;&#123; 0.5 &#125;&#125; //：对两个数做除法，返回整数商。 &#123;&#123; 20 // 7 &#125;&#125; 等于 2 %：计算整数除法的余数。 &#123;&#123; 11 % 7 &#125;&#125; 等于 4 *：用右边的数乘左边的操作数。 &#123;&#123; 2 * 2 &#125;&#125; 会返回 4 。 也可以用于重 复一个字符串多次。&#123;&#123; ‘=’ * 80 &#125;&#125; 会打印 80 个等号的横条 **：取左操作数的右操作数次幂。 &#123;&#123; 2**3 &#125;&#125; 会返回 8 Jinja2比较操作符 == 比较两个对象是否相等 != 比较两个对象是否不等 &gt; 如果左边大于右边，返回 true &gt;= 如果左边大于等于右边，返回 true &lt; 如果左边小于右边，返回 true &lt;= 如果左边小于等于右边，返回 true 逻辑运算符 对于 if 语句，在 for 过滤或 if 表达式中，它可以用于联合多个表达式 and 如果左操作数和右操作数同为真，返回 true or 如果左操作数和右操作数有一个为真，返回 true not 对一个表达式取反（见下） (expr) 表达式组 [&#39;list&#39;, &#39;of&#39;, &#39;objects&#39;]: 一对中括号括起来的东西是一个列表。列表用于存储和迭代序列化的数据。 例如 你可以容易地在 for循环中用列表和元组创建一个链接的列表 &lt;ul&gt; &#123;% for href, caption in [('index.html', 'Index'), ('about.html', 'About'), ('downloads.html', 'Downloads')] %&#125; &#123;&#123; caption &#125;&#125; &#123;% endfor %&#125; &lt;/ul&gt; (&#39;tuple&#39;, &#39;of&#39;, &#39;values&#39;): 元组与列表类似，只是你不能修改元组。 如果元组中只有一个项，你需要以逗号结尾它。 元组通常用于表示两个或更多元素的项。更多细节见上面的例子 &#123;&#39;dict&#39;: &#39;of&#39;, &#39;key&#39;: &#39;and&#39;, &#39;value&#39;: &#39;pairs&#39;&#125;: Python 中的字典是一种关联键和值的结构。 键必须是唯一的，并且键必须只有一个 值。 字典在模板中很少使用，罕用于诸如 xmlattr() 过滤器之类 true / false: true 永远是 true ，而 false 始终是 false template 的使用template功能：根据模块文件动态生成对应的配置文件 &gt; template文件必须存放于templates目录下，且命名为 .j2 结尾 &gt; yaml/yml 文件需和templates目录平级，目录结构如下： ./ ├── temnginx.yml └── templates └── nginx.conf.j2 template示例示例：利用template 同步nginx配置文件 准备templates/nginx.conf.j2文件 vim temnginx.yml - hosts: websrvs remote_user: root tasks: - name: template config to remote hosts template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf ansible-playbook temnginx.yml Playbook中template变更替换修改文件nginx.conf.j2 下面行为 worker_processes &#123;&#123; ansible_processor_vcpus &#125;&#125;; cat temnginx2.yml - hosts: websrvs remote_user: root tasks: - name: template config to remote hosts template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf ansible-playbook temnginx2.yml Playbook中template算术运算算法运算： 示例： vim nginx.conf.j2 worker_processes &#123;&#123; ansible_processor_vcpus**2 &#125;&#125;; worker_processes &#123;&#123; ansible_processor_vcpus+2 &#125;&#125;; when 实现条件判断条件测试:如果需要根据变量、facts或此前任务的执行结果来做为某task执行与否的前提时要用到条件测试, 通过when语句实现，在task中使用，jinja2的语法格式 when语句 在task后添加when子句即可使用条件测试；when语句支持Jinja2表达式语法 示例： tasks: - name: &quot;shutdown RedHat flavored systems&quot; command: /sbin/shutdown -h now when: ansible_os_family == &quot;RedHat&quot; 当系统属于红帽系列,执行command模块 when语句中还可以使用Jinja2的大多&quot;filter&quot;， 例如要忽略此前某语句的错误并基于其结果(failed或者success)运行后面指定的语句， 可使用类似如下形式： tasks: - command: /bin/false register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped 此外，when语句中还可以使用facts或playbook中定义的变量 示例：when条件判断- hosts: websrvs remote_user: root tasks: - name: add group nginx tags: user user: name=nginx state=present - name: add user nginx user: name=nginx state=present group=nginx - name: Install Nginx yum: name=nginx state=present - name: restart Nginx service: name=nginx state=restarted when: ansible_distribution_major_version == &quot;6&quot; 示例：when条件判断示例： tasks: - name: install conf file to centos7 template: src=nginx.conf.c7.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == &quot;7&quot; - name: install conf file to centos6 template: src=nginx.conf.c6.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == &quot;6&quot; Playbook中when条件判断--- - hosts: srv120 remote_user: root tasks: - name: template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version == &quot;7&quot; 迭代：with_items迭代：当有需要重复性执行的任务时，可以使用迭代机制 &gt; 对迭代项的引用，固定变量名为&quot;item&quot; &gt; 要在task中使用with_items给定要迭代的元素列表 &gt; 列表格式： 字符串 字典 示例示例： 创建用户 - name: add several users user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel #&#123;&#123; item &#125;&#125; 系统自定义变量 with_items: # 定义&#123;&#123; item &#125;&#125; 的值和个数 - testuser1 - testuser2 上面语句的功能等同于下面的语句： - name: add user testuser1 user: name=testuser1 state=present groups=wheel - name: add user testuser2 user: name=testuser2 state=present groups=wheel with_items中可以使用元素还可为hashes 示例： - name: add several users user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_items: - &#123; name: &#39;testuser1&#39;, groups: &#39;wheel&#39; &#125; - &#123; name: &#39;testuser2&#39;, groups: &#39;root&#39; &#125; ansible的循环机制还有更多的高级功能，具体请参见官方文档 http://docs.ansible.com/playbooks_loops.html 示例：迭代示例：将多个文件进行copy到被控端 --- - hosts: testsrv remote_user: root tasks - name: Create rsyncd config copy: src=&#123;&#123; item &#125;&#125; dest=/etc/&#123;&#123; item &#125;&#125; with_items: - rsyncd.secrets - rsyncd.conf 示例：迭代- hosts: websrvs remote_user: root tasks: - name: copy file copy: src=&#123;&#123; item &#125;&#125; dest=/tmp/&#123;&#123; item &#125;&#125; with_items: - file1 - file2 - file3 - name: yum install httpd yum: name=&#123;&#123; item &#125;&#125; state=present with_items: - apr - apr-util - httpd 示例：迭代- hosts：websrvs remote_user: root tasks - name: install some packages yum: name=&#123;&#123; item &#125;&#125; state=present with_items: - nginx - memcached - php-fpm 示例：迭代嵌套子变量- hosts：websrvs remote_user: root tasks: - name: add some groups group: name=&#123;&#123; item &#125;&#125; state=present with_items: - group1 - group2 - group3 - name: add some users user: name=&#123;&#123; item.name &#125;&#125; group=&#123;&#123; item.group &#125;&#125; state=present with_items: - &#123; name: &#39;user1&#39;, group: &#39;group1&#39; &#125; - &#123; name: &#39;user2&#39;, group: &#39;group2&#39; &#125; - &#123; name: &#39;user3&#39;, group: &#39;group3&#39; &#125; with_itmes 嵌套子变量with_itmes 嵌套子变量 示例 --- - hosts: testweb remote_user: root tasks: - name: add several users user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_items: - &#123; name: &#39;testuser1&#39; , groups: &#39;wheel&#39;&#125; - &#123; name: &#39;testuser2&#39; , groups: &#39;root&#39;&#125; Playbook字典 with_items- name: 使用ufw模块来管理哪些端口需要开启 ufw: rule: “&#123;&#123; item.rule &#125;&#125;” port: “&#123;&#123; item.port &#125;&#125;” proto: “&#123;&#123; item.proto &#125;&#125;” with_items: - &#123; rule: &#39;allow&#39;, port: 22, proto: &#39;tcp&#39; &#125; - &#123; rule: &#39;allow&#39;, port: 80, proto: &#39;tcp&#39; &#125; - &#123; rule: &#39;allow&#39;, port: 123, proto: &#39;udp&#39; &#125; - name: 配置网络进出方向的默认规则 ufw: direction: &quot;&#123;&#123; item.direction &#125;&#125;&quot; policy: &quot;&#123;&#123; item.policy &#125;&#125;&quot; state: enabled with_items: - &#123; direction: outgoing, policy: allow &#125; - &#123; direction: incoming, policy: deny &#125; Playbook中template for if when循环&#123;% for vhost in nginx_vhosts %&#125; server &#123; #重复执行server代码 listen &#123;&#123; vhost.listen | default('80 default_server') &#125;&#125;; &#123;% if vhost.server_name is defined %&#125; server_name &#123;&#123; vhost.server_name &#125;&#125;; &#123;% endif %&#125; &#123;% if vhost.root is defined %&#125; root &#123;&#123; vhost.root &#125;&#125;; &#123;% endif %&#125; &#123;% endfor %&#125; 示例// temnginx.yml --- - hosts: testweb remote_user: root vars: # 调用变量 nginx_vhosts: - listen: 8080 #列表 键值对 //templates/nginx.conf.j2 &#123;% for vhost in nginx_vhosts %&#125; server &#123; listen &#123;&#123; vhost.listen &#125;&#125; &#125; &#123;% endfor %&#125; 生成的结果 server &#123; listen 8080 &#125; 示例// temnginx.yml --- - hosts: mageduweb remote_user: root vars: nginx_vhosts: - web1 - web2 - web3 tasks: - name: template config template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf // templates/nginx.conf.j2 &#123;% for vhost in nginx_vhosts %&#125; server &#123; listen &#123;&#123; vhost &#125;&#125; &#125; &#123;% endfor %&#125; 生成的结果： server &#123; listen web1 &#125; server &#123; listen web2 &#125; server &#123; listen web3 &#125; rolesroles ansible自1.2版本引入的新特性，用于层次性、结构化地组织playbook。 roles能够根据层次型结构自动装载变量文件、tasks以及handlers等。 要使用roles只需要在playbook中使用include指令即可。 简单来讲，roles就是通过分别将变量、文件、任务、模板及处理器放置于单独的目录中， 并可以便捷地include它们的一种机制。 角色一般用于基于主机构建服务的场景中，但也可以是用于构建守护进程等场景中 复杂场景：建议使用roles，代码复用度高 变更指定主机或主机组 如命名不规范维护和传承成本大 某些功能需多个Playbook，通过includes即可实现 Roles角色(roles)：角色集合 roles/ mysql/ httpd/ nginx/ memcached/ 可以互相调用 Ansible Roles目录编排 roles目录结构每个角色，以特定的层级目录结构进行组织 roles目录结构： playbook.yml 调用角色 roles/ project/ (角色名称) tasks/ files/ vars/ templates/ handlers/ default/ 不常用 meta/ 不常用 Roles各目录作用/roles/project/ :项目名称,有以下子目录 files/ ：存放由copy或script模块等调用的文件 templates/：template模块查找所需要模板文件的目录 tasks/：定义task,role的基本元素，至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 handlers/：至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 vars/：定义变量，至少应该包含一个名为main.yml的文件； 其它的文件需要在此文件中通过include进行包含 meta/：定义当前角色的特殊设定及其依赖关系,至少应该包含一个名为main.yml的文件， 其它文件需在此文件中通过include进行包含 default/：设定默认变量时使用此目录中的main.yml文件 roles/appname 目录结构 tasks目录：至少应该包含一个名为main.yml的文件，其定义了此角色的任务列表； 此文件可以使用include包含其它的位于此目录中的task文件 files目录：存放由copy或script等模块调用的文件； templates目录：template模块会自动在此目录中寻找Jinja2模板文件 handlers目录：此目录中应当包含一个main.yml文件，用于定义此角色用到的各handler； 在handler中使用include包含的其它的handler文件也应该位于此目录中； vars目录：应当包含一个main.yml文件，用于定义此角色用到的变量； meta目录：应当包含一个main.yml文件，用于定义此角色的特殊设定及其依赖关系； ansible1.3及其以后的版本才支持； default目录：为当前角色设定默认变量时使用此目录；应当包含一个main.yml文件 roles/example_role/files/ 所有文件，都将可存放在这里 roles/example_role/templates/ 所有模板都存放在这里 roles/example_role/tasks/main.yml： 主函数，包括在其中的所有任务将被执行 roles/example_role/handlers/main.yml：所有包括其中的 handlers 将被执行 roles/example_role/vars/main.yml： 所有包括在其中的变量将在roles中生效 roles/example_role/meta/main.yml： roles所有依赖将被正常登入 创建role创建role的步骤 (1) 创建以roles命名的目录 (2) 在roles目录中分别创建以各角色名称命名的目录，如webservers等 (3) 在每个角色命名的目录中分别创建files、handlers、meta、tasks、templates和vars目录； 用不到的目录可以创建为空目录，也可以不创建 (4) 在playbook文件中，调用各角色 实验: 创建httpd角色1&gt; 创建roles目录 mkdir roles/&#123;httpd,mysql,redis&#125;/tasks -pv mkdir roles/httpd/&#123;handlers,files&#125; 查看目录结构 tree roles/ roles/ ├── httpd │ ├── files │ ├── handlers │ └── tasks ├── mysql │ └── tasks └── redis └── tasks 2&gt; 创建目标文件 cd roles/httpd/tasks/ touch install.yml config.yml service.yml 3&gt; vim install.yml - name: install httpd package yum: name=httpd vim config.yml - name: config file copy: src=httpd.conf dest=/etc/httpd/conf/ backup=yes vim service.yml - name: start service service: name=httpd state=started enabled=yes 4&gt; 创建main.yml主控文件,调用以上单独的yml文件, main.yml定义了谁先执行谁后执行的顺序 vim main.yml - include: install.yml - include: config.yml - include: service.yml 5&gt; 准备httpd.conf文件,放到httpd单独的文件目录下 cp /app/ansible/flies/httpd.conf ../files/ 6&gt; 创建一个网页 vim flies/index.html &lt;h1&gt; welcome to weixiaodong home &lt;\\h1&gt; 7&gt; 创建网页的yml文件 vim tasks/index.yml - name: index.html copy: src=index.html dest=/var/www/html 8&gt; 将网页的yml文件写进mian.yml文件中 vim mian.yml - include: install.yml - include: config.yml - include: index.yml - include: service.yml 9&gt; 在handlers目录下创建handler文件mian.yml vim handlers/main.yml - name: restart service httpd service: name=httpd state=restarted 10&gt; 创建文件调用httpd角色 cd /app/ansidle/roles vim role_httpd.yml --- # httpd role - hosts: appsrvs remote_user: root roles: #调用角色 - role: httpd 11&gt; 查看目录结构 tree . httpd ├── files │ ├── httpd.conf │ └── index.html ├── handlers │ └── main.yml └── tasks ├── config.yml ├── index.yml ├── install.yml ├── main.yml └── service.yml 12&gt; ansible-playbook role_httpd.yml 针对大型项目使用Roles进行编排roles目录结构： playbook.yml roles/ project/ tasks/ files/ vars/ templates/ handlers/ default/ # 不经常用 meta/ # 不经常用 示例： nginx-role.yml roles/ └── nginx ├── files │ └── main.yml ├── tasks │ ├── groupadd.yml │ ├── install.yml │ ├── main.yml │ ├── restart.yml │ └── useradd.yml └── vars └── main.yml 示例roles的示例如下所示： site.yml webservers.yml dbservers.yml roles/ common/ files/ templates/ tasks/ handlers/ vars/ meta/ webservers/ files/ templates/ tasks/ handlers/ vars/ meta/ 实验： 创建一个nginx角色建立nginx角色在多台主机上来部署nginx需要安装 创建账号 1&gt; 创建nginx角色目录 cd /app/ansible/role mkdir nginx&#123;tesks,templates,hanslers&#125; -pv 2&gt; 创建任务目录 cd tasks/ touch insatll.yml config.yml service.yml file.yml user.yml 创建main.yml文件定义任务执行顺序 vim main.yml - include: user.yml - include: insatll.yml - include: config.yml - include: file.yml - include: service.yml 3&gt; 准备配置文件(centos7、8) ll /app/ansible/role/nginx/templates/ nginx7.conf.j2 nginx8.conf.j2 4&gt; 定义任务 vim tasks/install.yml - name: install yum: name=nginx vim tasks/config.yml - name: config file template: src=nginx7.conf.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version==&quot;7&quot; notify: restrat - name: config file template: src=nginx8.conf.j2 dest=/etc/nginx/nginx.conf when: ansible_distribution_major_version==&quot;8&quot; notify: restrat vim tasks/file.yml 跨角色调用file.yum文件,实现文件复用 - name: index.html copy: src=roles/httpd/files/index.html dest=/usr/share/nginx/html/ vim tasks/service.yml - nmae: start service service: name=nginx state=started enabled=yes vim handlers/main.yml - name: restrat service: name=nginx state=restarted vim roles/role_nginix.yml --- #test rcle - hosts: appsrvs roles: - role: nginx 5&gt; 测试安装 ansible-playbook role_nginx.yml Roles案例Roles目录编排 Playbook中调用 playbook调用角色调用角色方法1： - hosts: websrvs remote_user: root roles: - mysql - memcached - nginx 调用角色方法2： 传递变量给角色 - hosts: remote_user: roles: - mysql - &#123; role: nginx, username: nginx &#125; #不同的角色调用不同的变量 键role用于指定角色名称 后续的k/v用于传递变量给角色 调用角色方法3：还可基于条件测试实现角色调用 roles: - &#123; role: nginx, username: nginx, when: ansible_distribution_major_version == &#39;7&#39; &#125; 通过roles传递变量通过roles传递变量 当给一个主机应用角色的时候可以传递变量，然后在角色内使用这些变量 示例： - hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: &#39;/web/htdocs/a.com&#39;, port: 8080 &#125; 向roles传递参数而在playbook中，可以这样使用roles： --- - hosts: webservers roles: - common - webservers 也可以向roles传递参数 示例： --- - hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: &#39;/opt/a&#39;, port: 5000 &#125; - &#123; role: foo_app_instance, dir: &#39;/opt/b&#39;, port: 5001 &#125; 条件式地使用roles甚至也可以条件式地使用roles 示例： --- - hosts: webservers roles: - &#123; role: some_role, when: &quot;ansible_os_family == &#39;RedHat&#39;&quot; &#125; Roles条件及变量等案例When条件 roles: - &#123;role: nginx, when: &quot;ansible_distribution_major_version == &#39;7&#39; &quot; ,username: nginx &#125; 变量调用 - hosts: zabbix-proxy sudo: yes roles: - &#123; role: geerlingguy.php-mysql &#125; - &#123; role: dj-wasabi.zabbix-proxy, zabbix_server_host: 192.168.37.167 &#125; 完整的roles架构// nginx-role.yml 顶层任务调用yml文件 --- - hosts: testweb remote_user: root roles: - role: nginx - role: httpd 可执行多个role cat roles/nginx/tasks/main.yml --- - include: groupadd.yml - include: useradd.yml - include: install.yml - include: restart.yml - include: filecp.yml // roles/nginx/tasks/groupadd.yml --- - name: add group nginx user: name=nginx state=present cat roles/nginx/tasks/filecp.yml --- - name: file copy copy: src=tom.conf dest=/tmp/tom.conf 以下文件格式类似： useradd.yml,install.yml,restart.yml ls roles/nginx/files/ tom.conf roles playbook tags使用roles playbook tags使用 ansible-playbook --tags=&quot;nginx,httpd,mysql&quot; nginx-role.yml 对标签进行挑选执行 // nginx-role.yml --- - hosts: testweb remote_user: root roles: - &#123; role: nginx ,tags: [ &#39;nginx&#39;, &#39;web&#39; ] ,when: ansible_distribution_major_version == &quot;6“ &#125; - &#123; role: httpd ,tags: [ &#39;httpd&#39;, &#39;web&#39; ] &#125; - &#123; role: mysql ,tags: [ &#39;mysql&#39;, &#39;db&#39; ] &#125; - &#123; role: marridb ,tags: [ &#39;mysql&#39;, &#39;db&#39; ] &#125; - &#123; role: php &#125; 实验: 创建角色memcachedmemcacched 当做缓存用,会在内存中开启一块空间充当缓存 cat /etc/sysconfig/memcached PORT=&quot;11211&quot; USER=&quot;memcached&quot; MAXCONN=&quot;1024&quot; CACHESIZE=&quot;64&quot; # 缓存空间默认64M OPTIONS=&quot;&quot; 1&gt; 创建对用目录 cd /app/ansible mkdir roles/memcached/&#123;tasks,templates&#125; -pv 2&gt; 拷贝memcached配置文件模板 cp /etc/sysconfig/memcached templates/memcached.j2 vim templates/memcached.j2 CACHESIZE=&quot;&#123;&#123;ansible_memtotal_mb//4&#125;&#125;&quot; #物理内存的1/4用做缓存 3&gt; 创建对应yml文件,并做相应配置 cd tasks/ touch install.yml config.yml service.yml 创建main.yml文件定义任务执行顺序 vim main.yml - include: install.yml - include: config.yml - include: service.yml vim install.yml - name: install yum: name=memcached vim config.yml - name: config file template: src=memcached.j2 dets=/etc/sysconfig/memcached vim service.yml - name: service service: name=memcached state=started enabled=yes 4&gt; 创建调用角色文件 cd /app/ansible/roles/ vim role_memcached.yml --- - hosts: appsrvs roles: - role: memcached 5&gt; 安装 ansible-playbook role_memcached.yml memcached端口号11211 其它功能委任（指定某一台机器做某一个task） delegate_to local_action (专指针对ansible命令执行的机器做的变更操作) 交互提示 prompt *暂停（java） wait_for Debug debug: msg=&quot;This always executes.&quot; Include Template 多值合并 Template 动态变量配置 Ansible Roles委任 delegate_to 交互提示 prompt 暂停 wait_for Debug debug: msg=&quot;This always executes.&quot; Include Template 多值合并 Template 动态变量配置 推荐资料http://galaxy.ansible.com https://galaxy.ansible.com/explore#/ http://github.com/ http://ansible.com.cn/ https://github.com/ansible/ansible https://github.com/ansible/ansible-examples 实验: 实现二进制安装mysql的卸载cat remove_mysql.yml --- # install mariadb server - hosts: appsrvs:!192.168.38.108 remote_user: root tasks: - name: stop service shell: /etc/init.d/mysqld stop - name: delete user user: name=mysql state=absent remove=yes - name: delete file: path=&#123;&#123;item&#125;&#125; state=absent with_items: - /usr/local/mysql - /usr/local/mariadb-10.2.27-linux-x86_64 - /etc/init.d/mysqld - /etc/profile.d/mysql.sh - /etc/my.cnf - /data/mysql ansible-playbook remove_mysql.yml","categories":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"https://skillixx.com/tags/Ansible/"},{"name":"Linux","slug":"Linux","permalink":"https://skillixx.com/tags/Linux/"}],"keywords":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"Mdadm命令详解","slug":"Mdadm","date":"2023-05-06T03:30:55.000Z","updated":"2023-05-09T05:32:16.688Z","comments":false,"path":"c901ebd9.html","link":"","permalink":"https://skillixx.com/c901ebd9.html","excerpt":"","text":"Linux内核中有一个md(multiple devices)模块在底层管理RAID设备，它会在应用层给我们提供一个应用程序的工具mdadm ，mdadm是linux下用于创建和管理软件RAID的命令。 mdadm命令常见参数解释： 参数 作用 -a 检测设备名称，添加磁盘 -n 指定设备数量 -l 指定RAID级别 -C 创建 -v 显示过程 -f 模拟设备损坏 -r 移除设备 -Q 查看摘要信息 -D 查看详细信息 -S 停止RAID磁盘阵列 搭建raid10阵列 新添加4块硬盘——在centos关机的情况下添加4块新的硬盘。 # ls /dev/sd* 下载mdadm # yum install mdadm -y 创建RAID10阵列 # mdadm -C -v /dev/md10 -l 10 -n 4 /dev/sd&#123;b,c,d,e&#125; 这里的选项是多个，对照上表查看。磁盘阵列名需要以md开头，这里创建的是md10。 查看阵列信息 # mdadm -D /dev/md10 格式化 # mkfs.xfs /dev/md10 挂载使用 # mount /dev/md10 /ken 写入到文件 方法一、 # echo “mount /dev/md10 /ken” &gt;&gt; /etc/rc.local 方法二、 # echo “/dev/md10 /ken xfs defaults 0 0 ” &gt;&gt; /etc/fstab mdadm管理RAID10阵列–模拟磁盘损坏后的处理方式 模拟损坏磁盘 # mdadm /dev/md10 -f /dev/sdd 选项f是用于模拟磁盘损坏。 # mdadm -D /dev/md10 查看详细信息，这时候已经显示磁盘损坏了。 重启 添加磁盘 # mdadm /dev/md10 -a /dev/sdd 选项a是用于添加磁盘。 # mdadm -D /dev/md10 添加成功，然后照常使用。 mdadm创建RAID阵列–RAID5+热备盘 添加四块磁盘并查看。 # ls /dev/sd* 创建磁盘阵列RAID5 # mdadm -C /dev/md5 -l 5 -n 3 -x 1 /dev/sd&#123;b,c,d,e&#125; 查看阵列信息 # mdadm -D /dev/md5 格式化 # mkfs.xfs /dev/md5 挂载 # mkdir /ken # mount /dev/md5 /ken 补充 在使用mdadm命令创建RAID阵列时，需要先将磁盘分区并格式化，然后再将分区设备加入到RAID阵列中。如果RAID阵列中的磁盘出现故障，可以使用mdadm命令进行磁盘的移除和添加，以及磁盘阵列的重建。 在创建RAID阵列时，需要注意以下几点： 磁盘数量必须是偶数，且至少需要两个磁盘。 磁盘容量应该相同，否则会浪费磁盘空间。 RAID级别的选择应该根据实际需求进行，不同的RAID级别有不同的优缺点。 在创建RAID阵列时，可以使用-x选项指","categories":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://skillixx.com/tags/Linux/"}],"keywords":[{"name":"常用工具","slug":"常用工具","permalink":"https://skillixx.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"ChatGPT使用","slug":"myChatGPT","date":"2023-02-26T14:26:01.000Z","updated":"2023-06-05T08:07:36.493Z","comments":false,"path":"36c4f4bb.html","link":"","permalink":"https://skillixx.com/36c4f4bb.html","excerpt":"","text":"一、获取openAI 的key1.关注公众号 2.输入关键字获取key​ 在消息输入框回复关键词“小张我需要ChatGPT的key” 二、使用方法​ 点击设置里面填充openAI key 三、测试结果再测点击设置，在对话框里面输入“你好”，有正常返回结果就可以了。 四、网站使用方法1.设置选项介绍 OpenAI API Key: 填写openAI的秘钥 系统角色指令：发送系统指令的类型，可以不用填写 思维发散程度： 根据自己需求自行调整 记录对话内容，刷新不会消失： 保留会话记录 开启连续对话，将加倍消耗Token: 作用是做到上下文内容联系 2.使用存在的问题介绍 常见网站错误如下，解决办法刷新网页 ​ TypeError: Failed to fetch​ error 对话数据不要太长，网页上下文联系错误长出现error错误，需要刷新网页","categories":[{"name":"AI话题","slug":"AI话题","permalink":"https://skillixx.com/categories/AI%E8%AF%9D%E9%A2%98/"}],"tags":[{"name":"ChatGPT","slug":"ChatGPT","permalink":"https://skillixx.com/tags/ChatGPT/"}],"keywords":[{"name":"AI话题","slug":"AI话题","permalink":"https://skillixx.com/categories/AI%E8%AF%9D%E9%A2%98/"}]},{"title":"老陕小张的技能介绍","slug":"myable","date":"2018-09-01T04:59:59.000Z","updated":"2023-05-19T06:30:21.743Z","comments":false,"path":"7d4ff147.html","link":"","permalink":"https://skillixx.com/7d4ff147.html","excerpt":"","text":"老陕小张我们是一家专注于部署服务器软件、网络环境、企业官网编写以及Linux和Windows系统优化的组织。我们的团队由一群技术精湛、经验丰富的IT专家组成，致力于为客户提供高质量的技术服务。 服务范围我们的服务范围涵盖了各种企业级软件的部署和优化，包括但不限于Web服务器、数据库服务器、邮件服务器、虚拟化平台等。我们还提供网络环境的规划和部署，确保客户的网络安全和稳定性。此外，我们还拥有一支专业的网站开发团队，能够为客户提供高质量的企业官网设计和开发服务。 技术团队我们的技术团队拥有丰富的Linux和Windows系统优化经验，能够为客户提供系统性能优化、安全加固、容灾备份等服务，确保客户的系统运行稳定、高效、安全。我们的目标是为客户提供最优质的技术服务，帮助客户提高业务效率，降低IT成本，让客户在激烈的市场竞争中获得更大的优势。我们相信，通过我们的专业技术和贴心服务，我们能够成为客户信赖的长期合作伙伴。 网络优化和部署我们的网络优化主要是针对家庭网络和中小型企业。我们的专业团队能够为客户提供网络性能优化、网络安全加固、网络拓扑规划等服务，确保客户的网络稳定、高效、安全。我们还能够为客户提供网络部署服务，包括网络设备的选型、配置、安装和调试，确保客户的网络环境能够满足业务需求。我们的目标是为客户提供全方位的网络服务，让客户的网络环境更加稳定、高效、安全。 联系我们总之，我们的团队致力于为客户提供最优质的技术服务，让客户在激烈的市场竞争中获得更大的优势。如果您需要我们的服务，请随时联系我们，我们将竭诚为您服务。","categories":[{"name":"关于我们","slug":"关于我们","permalink":"https://skillixx.com/categories/%E5%85%B3%E4%BA%8E%E6%88%91%E4%BB%AC/"}],"tags":[{"name":"关于我们","slug":"关于我们","permalink":"https://skillixx.com/tags/%E5%85%B3%E4%BA%8E%E6%88%91%E4%BB%AC/"}],"keywords":[{"name":"关于我们","slug":"关于我们","permalink":"https://skillixx.com/categories/%E5%85%B3%E4%BA%8E%E6%88%91%E4%BB%AC/"}]},{"title":"","slug":"404","date":"1998-02-26T04:00:01.000Z","updated":"2023-05-06T08:20:56.652Z","comments":true,"path":"/404.html","link":"","permalink":"https://skillixx.com/404.html","excerpt":"","text":"抱歉，页面未找到很抱歉，您所访问的页面不存在或已被删除。 请检查您输入的网址是否正确，或者返回主页继续浏览其他内容。 如果您认为这是一个错误，请联系我们的网站管理员进行处理。 谢谢您的访问！","categories":[],"tags":[],"keywords":[]}]}